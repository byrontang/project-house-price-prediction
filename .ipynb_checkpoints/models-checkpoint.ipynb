{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# House Price Prediction\n",
    "\n",
    "\n",
    "## Models\n",
    "\n",
    "This consists the codes for predicting house prices with regression models and ensemble methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in the data\n",
    "df = pd.read_csv('../project-house-price-prediction/data/train.csv')\n",
    "df_test = pd.read_csv('../project-house-price-prediction/data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "The data preprocessing follows the data exploration done in the notebook notebook data-exploration-and-preprocessing and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanHouseAttributes(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Apply rules during data exploration to clean house price dataset\"\"\"\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df_house_price, cols_to_drop, target_col):\n",
    "        # Age of building/remodle from YearBuilt and YearRemodAdd\n",
    "        df_house_price['AgeBuilding'] = 2012 - df_house_price['YearBuilt']\n",
    "        df_house_price['AgeRemodel'] = 2012 - df_house_price['YearRemodAdd']\n",
    "    \n",
    "        # Remove categories not exist in test.csv\n",
    "        df_filtered = df_house_price[(df_house_price['HouseStyle'] != '2.5Fin') &\n",
    "                                     (df_house_price['Exterior1st'] != 'Stone') &\n",
    "                                     (df_house_price['Exterior1st'] != 'ImStucc') &\n",
    "                                     (df_house_price['Exterior2nd'] != 'Other')]\n",
    "        \n",
    "        # Drop columns\n",
    "        df_dropped = df_filtered.drop(cols_to_drop + target_col, axis=1)\n",
    "            \n",
    "        # Fill NA for numeric columns\n",
    "        df_numeric = df_dropped.select_dtypes(include=['int64', 'float64']).apply(lambda x: x.fillna(x.mean()), axis=1)\n",
    "        \n",
    "        # Create dummies for non numeric columns\n",
    "        df_nonNumeric = pd.get_dummies(df_dropped.select_dtypes(include=['object']).fillna('NA'))\n",
    "        \n",
    "        # Create boolean variables for Alley, PoolQC, and Fence\n",
    "        df['HasAlley'] = list(1 if x is None else 0 for x in df['Alley'])\n",
    "        df['HasPool'] = list(1 if x is None else 0 for x in df['PoolQC'])\n",
    "        df['Fence'] = list(1 if x is None else 0 for x in df['Fence'])\n",
    "        \n",
    "        X = pd.concat([df_numeric, df_nonNumeric], axis=1)\n",
    "        y = df_filtered[target_col]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = ['Id', 'YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'TotalBsmtSF', \n",
    "             'TotRmsAbvGrd', 'MoSold', 'YrSold', 'Street', 'Alley', 'Utilities', \n",
    "             'LandSlope', 'Condition2', 'Heating', 'Functional', 'FireplaceQu', \n",
    "             'PoolQC', 'Fence', 'MiscFeature'            ]\n",
    "target_col = ['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>...</th>\n",
       "      <th>SaleType_ConLw</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleType_Oth</th>\n",
       "      <th>SaleType_WD</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>SaleCondition_AdjLand</th>\n",
       "      <th>SaleCondition_Alloca</th>\n",
       "      <th>SaleCondition_Family</th>\n",
       "      <th>SaleCondition_Normal</th>\n",
       "      <th>SaleCondition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>961.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 244 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  MasVnrArea  \\\n",
       "0        60.0         65.0   8450.0          7.0          5.0       196.0   \n",
       "1        20.0         80.0   9600.0          6.0          8.0         0.0   \n",
       "2        60.0         68.0  11250.0          7.0          5.0       162.0   \n",
       "3        70.0         60.0   9550.0          7.0          5.0         0.0   \n",
       "4        60.0         84.0  14260.0          8.0          5.0       350.0   \n",
       "\n",
       "   BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  1stFlrSF          ...            \\\n",
       "0       706.0         0.0      150.0     856.0          ...             \n",
       "1       978.0         0.0      284.0    1262.0          ...             \n",
       "2       486.0         0.0      434.0     920.0          ...             \n",
       "3       216.0         0.0      540.0     961.0          ...             \n",
       "4       655.0         0.0      490.0    1145.0          ...             \n",
       "\n",
       "   SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
       "0               0             0             0            1   \n",
       "1               0             0             0            1   \n",
       "2               0             0             0            1   \n",
       "3               0             0             0            1   \n",
       "4               0             0             0            1   \n",
       "\n",
       "   SaleCondition_Abnorml  SaleCondition_AdjLand  SaleCondition_Alloca  \\\n",
       "0                      0                      0                     0   \n",
       "1                      0                      0                     0   \n",
       "2                      0                      0                     0   \n",
       "3                      1                      0                     0   \n",
       "4                      0                      0                     0   \n",
       "\n",
       "   SaleCondition_Family  SaleCondition_Normal  SaleCondition_Partial  \n",
       "0                     0                     1                      0  \n",
       "1                     0                     1                      0  \n",
       "2                     0                     1                      0  \n",
       "3                     0                     0                      0  \n",
       "4                     0                     1                      0  \n",
       "\n",
       "[5 rows x 244 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = CleanHouseAttributes().transform(df, drop_cols, target_col)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23d8afe46a0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y.hist(bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"sklearn\"></a>\n",
    "## Regression\n",
    "\n",
    "### Probblem Definition\n",
    "**Input:** $x \\in \\mathbb{R}^{d}, d = 244$\n",
    "\n",
    "**Output:** $y \\in \\mathbb{R}$\n",
    "\n",
    "**Goal:** Find a function $f: \\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ such that $y \\approx f(x;w)$ for the data pair $(x, y)$. $f(x;w)$ is call a $\\textit{regression funciton}$. Its free parameters are $w$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Linear Regression\n",
    "\n",
    "A regression method is called $\\textit{linear}$ if the prediction $f$ is a linear function of the unknown parameters $w$. \n",
    "\n",
    "The linear regression has the form\n",
    "$$y_{i} \\approx f(x_{i};w) = w_{0} + x_{i}^{T}w,$$\n",
    "\n",
    "or in matrix form, \n",
    "$$y = \\mathbf{X}w,$$\n",
    "where a vector of 1 is attached in the first column of matrix $\\mathbf{X}$.\n",
    "\n",
    "With least square solution, we get the loss function for linear regression as\n",
    "$$L = \\sum_{i=1}^{n}\\left(y_{i}-x_{i}^{T}w\\right)^{2} = \\|y -\\mathbf{X}w\\|^{2} = (y-\\mathbf{X}w)^{T}(y-\\mathbf{X}w)$$\n",
    "\n",
    "If we take the gradient with respect to $w$, we find that\n",
    "$$\\nabla_{w}L = 2\\mathbf{X}^T\\mathbf{X}w-2\\mathbf{X}^Ty = 0 \\Rightarrow  w_{LS} = (\\mathbf{X}^T \\mathbf{X})^{âˆ’1}\\mathbf{X}^T y$$\n",
    "\n",
    "### Probablistic View of Linear Regression\n",
    "\n",
    "Gaussian density in $n$ dimensions: Assume a diagonal covariance matrix $\\Sigma = \\sigma^2I$. The density is \n",
    "$$p(y|\\mu, \\sigma^2) = \\frac{1}{(2\\pi\\sigma^2)^\\frac{n}{2}} \\exp (-\\frac{1}{2\\sigma^2}(y-\\mu)^T(y-\\mu)).$$\n",
    "Plug $\\mu=Xw$ into the multivariate Gaussian distribution and solve for $w$ using maximum likelihood.\n",
    "$$w_{ML} = \\operatorname*{arg\\,max}_w \\ln p(y|\\mu = Xw, \\sigma^2) \n",
    "= \\operatorname*{arg\\,max}_w -\\frac{1}{2\\sigma^2}\\|y-Xw\\|^2-\\frac{n}{2}\\ln(2\\pi\\sigma^2).$$\n",
    "\n",
    "**Least squres (LS) and maximum likelihood (ML) share the same solution.**\n",
    "\n",
    "$$\\text{LS: } \\operatorname*{arg\\,min}_w\\|y-Xw\\|^2  \\Leftrightarrow  \\text{ML: } \\operatorname*{arg\\,max}_w-\\frac{1}{2\\sigma^2}\\|y-Xw\\|^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.857646419466\n",
      "RMSE: 25676.4180144\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "print(\"R-squared:\", lr.score(X_test, y_test))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: See appendix for interpreting the coefficient of linear regression\n",
    "If the purpose of builing linear regression models is for interpretation. The package `statsmodels.api` would be a better option then the package `sklearn` for providing coefficients with p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              SalePrice   R-squared:                       0.863\n",
      "Model:                            OLS   Adj. R-squared:                  0.854\n",
      "Method:                 Least Squares   F-statistic:                     87.07\n",
      "Date:                Wed, 04 Sep 2019   Prob (F-statistic):               0.00\n",
      "Time:                        20:37:47   Log-Likelihood:                -16944.\n",
      "No. Observations:                1448   AIC:                         3.409e+04\n",
      "Df Residuals:                    1349   BIC:                         3.461e+04\n",
      "Df Model:                          98                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                -3640.1388   6085.568     -0.598      0.550   -1.56e+04    8298.067\n",
      "MSSubClass            -208.9931     31.307     -6.676      0.000    -270.409    -147.577\n",
      "LotFrontage             -3.0260      3.484     -0.868      0.385      -9.861       3.809\n",
      "LotArea                  0.5284      0.115      4.595      0.000       0.303       0.754\n",
      "OverallQual           1.107e+04   1194.577      9.267      0.000    8726.454    1.34e+04\n",
      "OverallCond           5254.6050   1004.179      5.233      0.000    3284.683    7224.527\n",
      "MasVnrArea              14.8452      5.609      2.647      0.008       3.841      25.849\n",
      "BsmtFinSF1              11.9239      4.967      2.401      0.016       2.181      21.667\n",
      "BsmtFinSF2               5.8868      6.829      0.862      0.389      -7.510      19.284\n",
      "BsmtUnfSF                2.7989      4.742      0.590      0.555      -6.503      12.101\n",
      "1stFlrSF                10.5984      7.305      1.451      0.147      -3.732      24.929\n",
      "2ndFlrSF                28.5651      6.781      4.212      0.000      15.262      41.868\n",
      "LowQualFinSF            -5.0275     17.015     -0.295      0.768     -38.406      28.351\n",
      "GrLivArea               34.1359      6.371      5.358      0.000      21.637      46.635\n",
      "BsmtFullBath          9413.0553   2372.508      3.968      0.000    4758.848    1.41e+04\n",
      "BsmtHalfBath          5252.5800   3702.547      1.419      0.156   -2010.795    1.25e+04\n",
      "FullBath              7974.7743   2698.269      2.956      0.003    2681.515    1.33e+04\n",
      "HalfBath              3535.4605   2561.345      1.380      0.168   -1489.191    8560.112\n",
      "BedroomAbvGr         -1901.1667   1465.995     -1.297      0.195   -4777.044     974.710\n",
      "KitchenAbvGr         -5213.3591   4943.661     -1.055      0.292   -1.49e+04    4484.740\n",
      "Fireplaces            3840.8579   1666.516      2.305      0.021     571.613    7110.103\n",
      "GarageCars            1.221e+04   2642.230      4.622      0.000    7028.138    1.74e+04\n",
      "GarageArea              -9.4120      9.043     -1.041      0.298     -27.151       8.327\n",
      "WoodDeckSF              28.0046      7.240      3.868      0.000      13.802      42.208\n",
      "OpenPorchSF              0.5573     14.135      0.039      0.969     -27.171      28.286\n",
      "EnclosedPorch            4.4697     15.620      0.286      0.775     -26.173      35.112\n",
      "3SsnPorch               34.1574     28.161      1.213      0.225     -21.086      89.401\n",
      "ScreenPorch             43.5261     15.559      2.798      0.005      13.004      74.048\n",
      "PoolArea                -8.1797     21.499     -0.380      0.704     -50.354      33.995\n",
      "MiscVal                  0.2835      1.657      0.171      0.864      -2.966       3.533\n",
      "AgeBuilding           -162.4229     84.084     -1.932      0.054    -327.373       2.528\n",
      "AgeRemodel             -98.1063     66.853     -1.467      0.142    -229.254      33.041\n",
      "Neighborhood_Blmngtn   272.5254   8122.787      0.034      0.973   -1.57e+04    1.62e+04\n",
      "Neighborhood_Blueste -1.324e+04   2.11e+04     -0.627      0.531   -5.46e+04    2.82e+04\n",
      "Neighborhood_BrDale  -5857.9867   8572.152     -0.683      0.494   -2.27e+04     1.1e+04\n",
      "Neighborhood_BrkSide -3612.9540   5145.401     -0.702      0.483   -1.37e+04    6480.904\n",
      "Neighborhood_ClearCr -2864.2585   6341.778     -0.452      0.652   -1.53e+04    9576.561\n",
      "Neighborhood_CollgCr -4037.9152   3453.578     -1.169      0.243   -1.08e+04    2737.051\n",
      "Neighborhood_Crawfor  1.752e+04   5137.624      3.411      0.001    7446.226    2.76e+04\n",
      "Neighborhood_Edwards -2.047e+04   3739.019     -5.476      0.000   -2.78e+04   -1.31e+04\n",
      "Neighborhood_Gilbert -9343.4957   4488.158     -2.082      0.038   -1.81e+04    -538.968\n",
      "Neighborhood_IDOTRR  -1.271e+04   6051.113     -2.101      0.036   -2.46e+04    -844.370\n",
      "Neighborhood_MeadowV -1.048e+04   9616.204     -1.090      0.276   -2.93e+04    8383.670\n",
      "Neighborhood_Mitchel -1.508e+04   4798.819     -3.143      0.002   -2.45e+04   -5666.403\n",
      "Neighborhood_NAmes   -1.518e+04   3085.211     -4.921      0.000   -2.12e+04   -9131.455\n",
      "Neighborhood_NPkVill -3557.2543   1.55e+04     -0.230      0.818   -3.39e+04    2.68e+04\n",
      "Neighborhood_NWAmes  -1.906e+04   4235.972     -4.500      0.000   -2.74e+04   -1.08e+04\n",
      "Neighborhood_NoRidge  4.353e+04   5762.850      7.553      0.000    3.22e+04    5.48e+04\n",
      "Neighborhood_NridgHt  4.165e+04   4732.657      8.801      0.000    3.24e+04    5.09e+04\n",
      "Neighborhood_OldTown -1.876e+04   4485.440     -4.182      0.000   -2.76e+04   -9958.040\n",
      "Neighborhood_SWISU   -1.149e+04   7488.286     -1.534      0.125   -2.62e+04    3203.269\n",
      "Neighborhood_Sawyer  -1.373e+04   4142.893     -3.315      0.001   -2.19e+04   -5605.079\n",
      "Neighborhood_SawyerW -7170.9594   4413.245     -1.625      0.104   -1.58e+04    1486.609\n",
      "Neighborhood_Somerst  1.308e+04   4292.267      3.048      0.002    4662.029    2.15e+04\n",
      "Neighborhood_StoneBr  5.313e+04   6787.364      7.828      0.000    3.98e+04    6.64e+04\n",
      "Neighborhood_Timber   1336.8292   5577.048      0.240      0.811   -9603.800    1.23e+04\n",
      "Neighborhood_Veenker  1.249e+04   9396.048      1.329      0.184   -5944.190    3.09e+04\n",
      "HouseStyle_1.5Fin    -7599.4212   3495.121     -2.174      0.030   -1.45e+04    -742.959\n",
      "HouseStyle_1.5Unf     5426.3658   8002.130      0.678      0.498   -1.03e+04    2.11e+04\n",
      "HouseStyle_1Story     5062.8871   3390.432      1.493      0.136   -1588.205    1.17e+04\n",
      "HouseStyle_2.5Unf     -1.22e+04   9471.744     -1.288      0.198   -3.08e+04    6385.865\n",
      "HouseStyle_2Story    -1.414e+04   3977.090     -3.555      0.000   -2.19e+04   -6336.550\n",
      "HouseStyle_SFoyer     1.147e+04   5434.186      2.111      0.035     811.677    2.21e+04\n",
      "HouseStyle_SLvl       8331.5675   4471.254      1.863      0.063    -439.800    1.71e+04\n",
      "Exterior1st_AsbShng    927.2624   1.31e+04      0.071      0.944   -2.48e+04    2.66e+04\n",
      "Exterior1st_AsphShn  -9042.1334    3.6e+04     -0.251      0.802   -7.97e+04    6.16e+04\n",
      "Exterior1st_BrkComm  -2.101e+04   2.84e+04     -0.738      0.460   -7.68e+04    3.48e+04\n",
      "Exterior1st_BrkFace   2.008e+04   7630.023      2.632      0.009    5110.874     3.5e+04\n",
      "Exterior1st_CBlock    3135.8273   1.45e+04      0.216      0.829   -2.54e+04    3.16e+04\n",
      "Exterior1st_CemntBd   -371.0114   1.77e+04     -0.021      0.983   -3.51e+04    3.44e+04\n",
      "Exterior1st_HdBoard  -1760.4546   6739.292     -0.261      0.794    -1.5e+04    1.15e+04\n",
      "Exterior1st_MetalSd   1549.3838   1.01e+04      0.153      0.878   -1.83e+04    2.14e+04\n",
      "Exterior1st_Plywood  -1341.2231   6837.263     -0.196      0.845   -1.48e+04    1.21e+04\n",
      "Exterior1st_Stucco    7486.0247   1.04e+04      0.718      0.473    -1.3e+04    2.79e+04\n",
      "Exterior1st_VinylSd  -7380.0551   9214.499     -0.801      0.423   -2.55e+04    1.07e+04\n",
      "Exterior1st_Wd Sdng  -2181.8387   6341.538     -0.344      0.731   -1.46e+04    1.03e+04\n",
      "Exterior1st_WdShing   6265.0701   8144.420      0.769      0.442   -9712.034    2.22e+04\n",
      "Exterior2nd_AsbShng    985.4459   1.27e+04      0.077      0.938    -2.4e+04     2.6e+04\n",
      "Exterior2nd_AsphShn   4586.6908   2.11e+04      0.217      0.828   -3.69e+04     4.6e+04\n",
      "Exterior2nd_Brk Cmn   6379.0820   1.99e+04      0.320      0.749   -3.27e+04    4.54e+04\n",
      "Exterior2nd_BrkFace  -7149.4081   8814.254     -0.811      0.417   -2.44e+04    1.01e+04\n",
      "Exterior2nd_CBlock    3135.8273   1.45e+04      0.216      0.829   -2.54e+04    3.16e+04\n",
      "Exterior2nd_CmentBd   5862.3950   1.78e+04      0.330      0.742    -2.9e+04    4.07e+04\n",
      "Exterior2nd_HdBoard    412.1018   6002.621      0.069      0.945   -1.14e+04    1.22e+04\n",
      "Exterior2nd_ImStucc     3.3e+04   1.06e+04      3.122      0.002    1.23e+04    5.37e+04\n",
      "Exterior2nd_MetalSd    825.2683   9875.398      0.084      0.933   -1.85e+04    2.02e+04\n",
      "Exterior2nd_Plywood   -920.7554   5497.905     -0.167      0.867   -1.17e+04    9864.617\n",
      "Exterior2nd_Stone    -3.125e+04   1.57e+04     -1.997      0.046   -6.19e+04    -544.966\n",
      "Exterior2nd_Stucco   -2.307e+04   9931.500     -2.323      0.020   -4.26e+04   -3589.926\n",
      "Exterior2nd_VinylSd   1.112e+04   8677.785      1.281      0.200   -5905.695    2.81e+04\n",
      "Exterior2nd_Wd Sdng   1032.3800   5491.627      0.188      0.851   -9740.677    1.18e+04\n",
      "Exterior2nd_Wd Shng  -8591.6205   6626.044     -1.297      0.195   -2.16e+04    4406.850\n",
      "Foundation_BrkTil    -2547.0869   4816.320     -0.529      0.597    -1.2e+04    6901.204\n",
      "Foundation_CBlock     2699.7382   4122.893      0.655      0.513   -5388.241    1.08e+04\n",
      "Foundation_PConc      5287.0398   4329.232      1.221      0.222   -3205.719    1.38e+04\n",
      "Foundation_Slab       -271.1209   7802.227     -0.035      0.972   -1.56e+04     1.5e+04\n",
      "Foundation_Stone      1.162e+04   1.16e+04      1.004      0.315   -1.11e+04    3.43e+04\n",
      "Foundation_Wood      -2.043e+04   1.57e+04     -1.302      0.193   -5.12e+04    1.04e+04\n",
      "HeatingQC_Ex          5393.3282   6365.907      0.847      0.397   -7094.824    1.79e+04\n",
      "HeatingQC_Fa          7278.3711   7119.432      1.022      0.307   -6687.990    2.12e+04\n",
      "HeatingQC_Gd          2098.8898   6413.899      0.327      0.744   -1.05e+04    1.47e+04\n",
      "HeatingQC_Po         -2.045e+04   2.64e+04     -0.773      0.439   -7.23e+04    3.14e+04\n",
      "HeatingQC_TA          2040.5452   6301.855      0.324      0.746   -1.03e+04    1.44e+04\n",
      "CentralAir_N           794.3913   3710.603      0.214      0.831   -6484.788    8073.571\n",
      "CentralAir_Y         -4434.5301   3802.367     -1.166      0.244   -1.19e+04    3024.664\n",
      "KitchenQual_Ex        2.569e+04   4024.639      6.383      0.000    1.78e+04    3.36e+04\n",
      "KitchenQual_Fa       -8150.8411   4766.268     -1.710      0.087   -1.75e+04    1199.262\n",
      "KitchenQual_Gd       -1.126e+04   2598.567     -4.334      0.000   -1.64e+04   -6164.340\n",
      "KitchenQual_TA       -9916.8553   2428.041     -4.084      0.000   -1.47e+04   -5153.708\n",
      "==============================================================================\n",
      "Omnibus:                      559.153   Durbin-Watson:                   1.857\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            74705.580\n",
      "Skew:                          -0.730   Prob(JB):                         0.00\n",
      "Kurtosis:                      38.158   Cond. No.                     7.52e+16\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 5.46e-23. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "X_sm = sm.add_constant(X)\n",
    "lr_sm = sm.OLS(y, X_sm)\n",
    "lr_sm = lr_sm.fit()\n",
    "print(lr_sm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Ridge Regression\n",
    "Least square solution is unbiased but potentially has high variance. The value in $w_{ML}$ may be huge. In general, we often want to constraint the model parameters. One way is to add regularization. Ridge Regression addresses variance issues with $w_{ML}$ by using the squared penalty on the gression coefficient vector $w$,\n",
    "$$w_{RR} = \\operatorname*{arg\\,min}_w \\|y-\\mathbf{X}w\\|^2+\\lambda\\|w\\|^2 = (\\lambda\\mathbf{I}+\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^Ty.$$\n",
    "\n",
    "### Probablisitc View: Ridge Regression and Bayesian Modeling\n",
    "Adding a $l2$ regularization term to linear regression is like defining a prior on the unknown parameter $w$ and trying to learn its posterior. \n",
    "\n",
    "In Bayesian setting, we can model the data as:\n",
    "\n",
    "**Likelihood:** $y \\sim N(Xw, \\sigma^2I)$\n",
    "\n",
    "**Prior:** $w \\sim N(0, \\lambda^{-1}I)$ Then \n",
    "$$p(w) = (\\frac{\\lambda}{2\\pi})^{\\frac{d}{2}} e^{-\\frac{\\lambda}{2}w^Tw}$$\n",
    "\n",
    "Maximum $\\textit{a poseriori}$ (MAP) estimation seeks the most probable value $w$ under the posterior:\n",
    "$$w_{MAP} = \\operatorname*{arg\\,max}_w\\ln p(w|y,X) = \\operatorname*{arg\\,max}_w\\ln p(y|w,X) + \\ln p(w)$$\n",
    "$$=\\operatorname*{arg\\,max}_w\\frac{1}{2\\sigma^2}(y-Xw)^T(y-Xw) - \\frac{\\lambda}{2}w^Tw + const.$$\n",
    "\n",
    "Take gradient of the function, we can get the solution for $w_{MAP}$ = $(\\lambda\\sigma^2I+X^TX)^{-1}X^Ty$.\n",
    "\n",
    "**Notice that $w_{MAP} = w_{RR}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.70000000000000007} 0.798337499746\n",
      "R-squared: 0.892846699556\n",
      "RMSE: 22276.810783\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'alpha': np.linspace(0, 10, 101)}\n",
    "ridge = Ridge(normalize=True)\n",
    "gs_ridge = GridSearchCV(ridge, param_grid, cv=5)\n",
    "gs_ridge.fit(X_train, y_train)\n",
    "print(gs_ridge.best_params_, gs_ridge.best_score_)\n",
    "\n",
    "y_pred = gs_ridge.predict(X_test)\n",
    "print(\"R-squared:\", gs_ridge.score(X_test, y_test))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sparse Regression (Lasso)\n",
    "The pentalty term of Lasso will select a small subset of the d dimensions and switch off the rest, encourasing sparse solutions.\n",
    "\n",
    "**LASSO:** Least Absolute Shrinkage and Selection Operator\n",
    "\n",
    "With the LASSO, we replac the $l_2$ penalty with an $l_1$ penalty:\n",
    "$$w_{lasso} = \\operatorname*{arg\\,min}_w \\|y-\\mathbf{X}w\\|^2+\\lambda\\|w\\|_1,$$\n",
    "where\n",
    "$$\\|w\\|_1 = \\sum_{j=1}^{d}|w_j|.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings from using Lasso\n",
    "import warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 10.0} 0.778958046344\n",
      "R-squared: 0.883019421248\n",
      "RMSE: 23275.9343009\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'alpha': np.linspace(0, 10, 11)}\n",
    "lasso = Lasso(normalize=True)\n",
    "gs_lasso = GridSearchCV(lasso, param_grid, cv=5)\n",
    "gs_lasso.fit(X_train, y_train)\n",
    "print(gs_lasso.best_params_, gs_lasso.best_score_)\n",
    "\n",
    "y_pred = gs_lasso.predict(X_test)\n",
    "print(\"R-squared:\", gs_lasso.score(X_test, y_test))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Elastic Net\n",
    "Elastic Net combines $l_1$ and $l_2$ penalties.\n",
    "$$w_{elastic} = \\operatorname*{argmin}_w \\|y-\\mathbf{X}w\\|^2+\\lambda_2\\|w\\|^2+\\lambda_1\\|w\\|_1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l1_ratio': 1, 'alpha': 1.0} 0.752483263323\n",
      "R-squared: 0.859179034362\n",
      "RMSE: 25537.8245446\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'alpha': np.linspace(0, 1, 5), 'l1_ratio': [0.1, 1]}\n",
    "en = ElasticNet()\n",
    "gs_en = GridSearchCV(en, param_grid, cv=5)\n",
    "gs_en.fit(X_train, y_train)\n",
    "print(gs_en.best_params_, gs_en.best_score_)\n",
    "\n",
    "y_pred = gs_en.predict(X_test)\n",
    "print(\"R-squared:\", gs_en.score(X_test, y_test))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison - Linear Regression, Ridge, Lasso, and Elastic Net\n",
    "#### Predictive Performance\n",
    "In general, regression models with regularization terms have better prediction, or generalization, than linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_variance = pd.DataFrame({})\n",
    "# Apply best models from grid search\n",
    "for (k,v) in zip(['Linear Regression', 'Ridge Regression', 'Sparse Regression', 'Elastic Net'],\n",
    "                 [lr, Ridge(alpha=0.7), Lasso(alpha=10), ElasticNet(alpha=1, l1_ratio=1)]):\n",
    "    cv_results = cross_val_score(v, X, y, cv=5)\n",
    "    df_variance[k] = cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23d8ee64ac8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_variance_plot = df_variance.melt()\n",
    "plt.plot(df_variance_plot['variable'], df_variance_plot['value'], 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficients - Quadratic Penalty (Ridge) vs Linear Penalty (Lasso)\n",
    "- Suppose $w_k$ is large, all other$w_j$ are very small but non-zero\n",
    "- Linear penalty: Penalty should keep $w_k$ and push other $w_j$ to zero\n",
    "- Quadratic penalty: Will favor entries $w_j$ with all have similar size, and so it will push $w_k$ towards small value.\n",
    "\n",
    "Overall, a quadratic penalty favors many small but non-zero values, and a linear penalty term achieves sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABDMAAAD8CAYAAABqxu/JAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3WeUHOd95/tvdc7dk3NAzjmQIAlSFDMlitIqOSjYli2t055dp2v7eFdeeS3LV7b3WqYtS7aSJUqkZJEiJWaCJAIBIg7SBGByTp1zV7wvZohAgEgCBAz5/5wzGEx1dT1Pp+qq3xNKsSwLIYQQQgghhBBCiLnCdr0rIIQQQgghhBBCCHE5JMwQQgghhBBCCCHEnCJhhhBCCCGEEEIIIeYUCTOEEEIIIYQQQggxp0iYIYQQQgghhBBCiDlFwgwhhBBCCCGEEELMKRJmCCGEEEIIIYQQYk6RMEMIIYQQQgghhBBzioQZQgghhBBCCCGEmFMc17sCv2iVlZVWa2vr9a6GEEIIIYQQQggh3uLgwYNRy7KqLrbeuy7MaG1t5cCBA9e7GkIIIYQQQgghhHgLRVEGL2U9GWYihBBCCCGEEEKIOUXCDCGEEEIIIYQQQswpEmYIIYQQQgghhBBiTpEwQwghhBBCCCGEEHOKhBlCCCGEEEIIIYSYUyTMEEIIIYQQQgghxJwiYYYQQgghhBBCCCHmFAkzhBBCiHeZrok0BdW43tUQQgghhLhiEmYIIYQQ7yKpgsZzxyboGE9f76oIIYQQQlwxCTOEEEKId5FYtgRAtqRf55oIIYQQQlw5CTOEEEKId5F4TgUgL2GGEEIIIeYwCTOEEEKId5HYbJghPTOEEEIIMZdJmCGEEEK8i7zZMyMnYYYQQggh5jAJM4QQQoh3CcuyTocZcjUTIYQQQsxhEmYIIYQQ7xLZko6qm4S9TlTdpKRLoCGEEEKIuUnCDCGEEOJd4s1eGU3lPgDyJQkzhBBCCDE3SZghhBBCvEu8Ofln82yYIZOACiGEEGKukjBDCCGEeJeIZ1W8LjuVARcAOVXCDCGEEELMTRJmCCGEEO8S8ZxKud+F3+0A5IomQgghhJi7JMwQQggh3gUsyyKWU6nwu3A7bDjtCjmZM0MIIYQQc9RVCTMURfmmoihTiqIcP2NZuaIoLymK0j37u2x2uaIoylcURelRFOWooijrz7jPp2fX71YU5dNnLN+gKMqx2ft8RVEU5UJlCCGEEOJsedWgqBmU+10oioLP5ZCeGUIIIYSYs65Wz4xvA/e/ZdmfAtssy1oEbJv9G+ABYNHsz2eBr8JMMAF8HrgJ2Ax8/oxw4quz6755v/svUoYQQgjxjpLKaxTUK+9J8eaVTCr8bgACbodMACqEEEKIOeuqhBmWZe0A4m9Z/DDwndn/fwf44BnL/8Oa8QYQURSlDrgPeMmyrLhlWQngJeD+2dtClmXtsSzLAv7jLds6XxlCCCHEO4ZpWvzwwDAvdkxc8TbevJJJ+ezkn3639MwQQgghxNx1LefMqLEsaxxg9nf17PIGYPiM9UZml11o+ch5ll+oDCGEEOIdYzRZIFvS6Y/myBS1K9pGPFfC7bThd9kB8Lvt5H6Onh5CCCGEENfT9ZgAVDnPMusKll96gYryWUVRDiiKcmB6evpy7iqEEEJcdz1TWew2BcuCjrH0FW0jllUp983MlwEzw0xU3aSkS6AhhBBCiLnnWoYZk7NDRJj9PTW7fARoOmO9RmDsIssbz7P8QmWcxbKsr1uWtdGyrI1VVVU/14MSQgghfpEsy6JnKsu8Sj+NZV7ax9LMjLq8PG9elvVNPtfM5VnzckUTIYQQQsxB1zLMeBp484oknwaeOmP5p2avanIzkJodIvICcK+iKGWzE3/eC7wwe1tGUZSbZ69i8qm3bOt8ZQghhBDvCOOpItmSzsLqACsbwqQKGiOJwmVto6Aa5FWDisDpMCPgngkzZBJQIYQQQsxFjquxEUVRfgC8B6hUFGWEmauSfAn4oaIonwGGgI/Orv4s8CDQA+SBXwewLCuuKMpfAftn1/uCZVlvTir628xcMcULPDf7wwXKEEIIId4RumeHmMyr9GO3KbgcNtrH0jSV+y55G/H87OSfs1cyIdmO3zEz/VROlTBDCCGEEHPPVQkzLMv65be56a7zrGsBv/s22/km8M3zLD8ArDzP8tj5yhBCCCHeCd4cYtJS4cPjnJm4c2ltkM7xNEWt6tSyi4ln3wwzXKAmYOhHBKruBOrIyTATIYQQQsxB12MCUCGEEEJcgqlMiXRBY0FV4NSyFfVhNMPi5GTmkrcTy5Vw2hVCHgcUxgFwaVEcNkUuzyqEEEKIOUnCDCGEEOIG1T2ZxaYoZ4UZNSE3lUE37ZdxVZOZyT/dM1cyKU4CoJSi+N0OCTOEEEIIMSdJmCGEEELcgGaGmGRoLPPidZ0eTqIoCivqQ0ykikxlihfdTio/M2FobXh2vozCxMzvUpSAyy4TgAohhBBiTpIwQwghhLgBRbMqibzGoprAObctqw3hcth4uWMK3TAvuJ2dPdPYFNjUWj6zoDgJih1MjbAzJz0zhBBCCDEnSZghhBBC3IB6prIoCmcNMXmT12XnvhU1TKaL7OieftttDMfzdE9m2dhaTtDjBKOIWYqzMz5GqpQiYkuSU2UCUCGEEELMPRJmCCGEEDegVEEl6HHid5//wmMLq4NsaCnjyHCKrolz588wTYsd3dMEPQ42tJTNLCxOkiqlOKbCVG6KkJJE1U1U/cK9O4QQQgghbjQSZgghhBA3INMCh0254Dq3LqykIeLl5Y5JotnSWbd1jKeZSpfYuqgKp332674wQaqYImWPENc0AlYCQIaaCCGEEGLOkTBDCCGEuAEZpoXtImGG3abw4Oo6XA4bPz0yxv6BOIOxHKm8xu7eKPURD4vPnHOjOElULVBSXEzoBl4zBiCTgAohhBBizjl/31UhhBBCXFemZXGRLAOAgNvBg6vqeLF9kl3d0bNu+8CahpnLsb65zfwYY5pO2B8hU/JglAbBssjLvBlCCCGEmGMkzBBCiGvJskBLgqvsmhZT1AyePjzKbYuqqI94r2lZ4hfDMC3syiWkGUBjmY/fuG0eRc1gOlNiKlPE47RTG/acXskyyaR7SSlebm68mWOZTkpaEpeVlZ4ZQgghxDXSMZYm5HXQWOa73lV5x5FhJkIIcS3F9kPXP0LswDUt5nj/IPVjX2Gw/9qWI35xLmWYyVt5nHaayn1saClnRX347BtLMZKFKFl7gDW1azDdFeS1LEESMmeGEEIIcQ1ohsm2zkl2vqXnpLg6JMwQQohryEx1kSlpWKM/hcTha1KGZphE+17CbpUoTh3EsqxrUo74xbIsLrlnxiUpTpIqpvAEWvA5fUTCi8ioGcocKQkzhBBCiGtgOJ5HNy0mUkUyRe16V+cdR8IMIYS4VkyNnsH9fK17gj1TPor9T0Dy+FUv5sTgEKFiO2WBAO5CP8lM5qqXIa6NCwVPhmVhv8yeGRdiFsZIljJUl68AoDYyn6SuESQqw0wuUbqg8uVtrzKayF3vqgghhJgDBmI5bLMNE73T8t1xtUmYIYQQ10p2gP54H12qzr9MFtgx6mbs+KOYiY6rVoRpWoz3vETA46JuxS+hYDI5dvSqbV9cO4mcyr9u72M4nj/v7YZpcTU7ZqSSJ0grLlrK5gPQEGwgZ/NhN4ZlAtBL9NOOg7w88ATfP/zy9a6KEEKIG5xlWfRH87RW+ij3u+idyl72NnTDlB63FyBhhhBCXCP5+HEm8wkqq1fTXGPysuXneNzLiUOPgnl1WsJ7Rofw549R1nQTbYU4hsNNdlLCjLngwGCComaQKpy/26l5lXtmpJInydoCtIRbAKgP1s+EGdowWen6elEl3eDF7l3YFNg9vI90Ub3eVRLnYxpw8l9gatf1rol4N7FMSB4Do3i9ayJuIPGcSrqgMa/Sz4KqACOJAkXt0hsPDNPiB/uHebJtFNOUQON8JMwQQrwzaVkYeWrm9zW2rz9+3tb13sHtjJsBPrjiYT607CG8wQT9vjDJTJp89NjPXa5lWYydfBGvy0m/28drQ9vpQ0VPdWNockB1I0sXNTrH08BMaHE+51zNxLJmfq6EniObG8fmqyfoDgLgd/mxe2oxjCSWlkHVzSvb9rvErr4+orl+fqVBAS3Kc52HrneVrphmXFl4ZVkW8dwNHuKku7CKkzC9A/Tz93oS4kpMpov0Tb/NMUXiCLne/8Aaf/EXWylxQxuIzQwraanws7A6gGlZ9F3GUJPO8TTRTInBWJ79A/FrVc05TcIMIcTPTdVNNOPGOhHKDfyUzo7t5CbeuKblJPMqr/dEeb3nLbNUqwkmY12k7E2sq5/HpoZN3NJ0C73GFONqlujQnp+77OGJEVyZYziqV7B99BBeh5deS6ekpZkev7ywJJlXOT6a4uWOSb77xiBf295L96TMvXGtHBpMYMy2shhv09piWpy+momhEj/2RTJ9372iQMMqTJAsJimLLD1reTC0gJKRw2clSOYv8SQ1feIXEhLeSEzT4umOHdzqneJj1X7uD0zywsmdc7KlbPfwbr6060v0J/ov+76dY2n+c+deem7gfUNhcgc7x9roi52A6devd3XeVmxwJ2PHH59p0Rc3vIJq8GTbKD87Ok76rT3ZTI3x3u+zZ2Q//X1PQHH6+lRS3HD6o3kqAy7CXic1ITdBj4OetwvE3sIwLfb2x6kJullaG+SNvjijycI1rvHcI2GGEOLnMhzP872dR3j6wIkbZkyfleqip3snHbGTjPZvv/LW7EvQOT5zUD+eKpI4o8UyHW0jVkhSVnUrbqcdgHsX3Mu6+pUcLOWITR6FUuyKy9V1g6HOZ3A5HLRZBVx2F59Z/xkcwTrG1Sip8SOXtJ2iZrCtc5Jv7x7gpY5JTk5lCLjtBD1Onjk2zsHB+GW9rgXVYF9/nJJ+fedgaBtK8O3X++kcT98w78s35VWd46MpFlYHKOpZDPP8JzPmGT0zpnsf5djgyxzr+h756b2XXWYi0Ylu6tRUrjlreUX5ElBUPIzzStfU2wYrbypmRjm666tMHv3GVRsqNRe0j0eJJfZyTxm4fXXcUhbAkWtj//DA9a7aZTkRPcH+E4+zMneIFzu+j2pcei8L07ToOvYDquJ/zdG2xy/6XrkezMIEXYPPsy3hY1ssS3b8lRsyeMtMd9Fz5HH6Tr7KVN+2610dcQl2dE/jLI5Spvdw4C0t5PnxV2gfPcDj8UYOTw6QG37qF1YvzTB5tWuKset8klvSDY6Ppq77d/+NpKQbjCULtFb6AVAUhQVVAYZiuUtqADw+miKTL3Cv91nuDuwk5LHx3LHxyxqm8m7wjggzFEW5X1GUE4qi9CiK8qfXuz5C3Cgu5yRON8zLPjg9OpJkx96XWZn9LuUTj9I+fPnX0LYs6+qebBolxjv/kwPxEV4tBeifbIPcwNXb/hksy6JrIk1l0I2iQOdE+tRtA8OvktCcrGu549QyRVH4wJIPkAvOpyfZQ3Fq3xWVq+s6+3c/ij3dTr6imb7cNPcuuJdKXyW3ttxKv6mQnG6DC5yoWJbF8dEU3949wPHRNOuay/j0La389h0L+NC6Rj66sZFF1UF2nIzy6ompS26B3tM300tlT+/FgxrLsni1a4pXuiY5OpJkNFm4KgdCvdNZtp+cJq8ZPH98gh8dHCGaLf3c271aDg8lyWt5ovoOXhv7FgOp3vOuZ1gWNhvkY0fo6XmMmG8xcVuAjiN/h1G8vO6msUQHJZuL5oqze2bUhRdi2V0sKYsyniqyt+/Cr1vviV0MpgfpGzmKOfrMZdXhF8kwrbfdn+VVnVe6Js9tXb2AnxzbyRZHL4tqlsGC32RR02a2OEd4tn3unIhOZifZduzr3GIOcEdFEy2JnezoufTXsGfgGHr0h5RseUrT36Gt47VrV9krdKTjG4xlk+Rd72dHpo7OqQ6s6Rtr7gy9mKRj/9c4luljb36Uk8cfQ8sMXe9qncOyLI6OJPnO633v+l56Q7E8I8Pt3O15jlsd25ga2HXqEpuWluVk1zc5lvNRXflr7MlV09nzLGQHrkrZlmWx4+Q0TxwaOe9QwNd7ohweTvJk2yiT6eszvDRT1PjRgRGePT7ED/YOMZ25+Pft1Tru0wyTgWgO/QbrHQwzjX2GadFa4Yf0ScgNs6AqgGZYDMYuPARON0z2D8RZ5zqI3xjASBzi4Zp2ciWDlzomb7hGmuvJcb0r8PNSFMUO/DNwDzAC7FcU5WnLsq7e5QLmCtMgO7mfZGwI1RaiqMz8lJc30VIVQrma0+JfRUOpIYZSQzQEG2gMNeK0Oy/5vpZlkSgm0AyNoloimopSGaikpar5Gtb42ihqBl0TGTrH0zjtNuZV+plf6afM77q0DegFCpM7cDqDZLyraRvN0TmeYVNrOZvnlV/wrtFsiScOjVAd9PDw2vpz3iujyQIvtU9Q5ndRG/JQG/bQO5Ui1fsMy20HyPs1zOQAg+1PMr/2N/C5Lr5rsSyLk5NZXu+JUtAMqoNuasMeakMemsp9eGZ7M1yu4vCLHBk6yD6lmqra5YxO/ieTQ9uoWf6bV7S9C5lIF0nmNe6cp9Fjc9A1nmHL/AowDSYmDpB2zGdFff1Z9/G7/Hxg5Yd5Y1cbXSd+wtqGe8F26Y/V0DXaXv8GJNqJNG/hqdwgrZFW1tauBWBL4xa2+Z5kPN1NMXECT+Wqc7ahGyZPHxljMJanIeLlzqXVVAXdZ63jtNt4cFUtIa+DAwMJCqrJ+1bXXbBuybzKsZE0bqeNI8MpVtSHz9numbqnshweTuK0K2i6SdgcIWwOY4VWUFnVQlO5j4aI97LeC9OZEs8fn6A66OEjGxo5MZFhV0+UR98Y4qb55dw8v+KSt3UtlHSD508cYKS4m7xrpj0hVUydd13DtLCbeTqPfIkEbrZs/AvimUEm2j5PR9sXWXXzl7mky51YFtlEJ6a7mrA7fNZNdaF6Dtv9NDLG8voQ+wbiNJX7aCr3nbOZQkllePBFOrQi2VKO1sGd1PmboHz95T8R562mRUEzLmn/cbHtPHV4lFxJ52ObmnA77Gfd9lLHJH3TOXIlg4fW1F9gSzNGE3kyUz/ltrCLyPyPg8OHp/WjLOp5lcHpnzGR+ji14eBFt1PSDV7pnGJRTZCF1YFz6tw5niFd1NjUWn5VJ37NlXTaxyd5+djfs1Y7SrjmToaD9+Gb+jL9R77KY6k65lctZmNL2elhTW9hqnm6D/89aUwWbfxTevZ/he4j/4f5ja2UR+Zdtbq+nfFUgY6xNHnVQNVNSrqJx2njA2vqcdhnPkc90+3Ex14h5VjN/NAWFKef7Ylv0Tz0DDVVt4Lz/K9Rz1SGbMlgTWP4so6TLMuiYzxNqqCxvrns0vZTlsnB3f/IiehBRqq24HSX0T7yHJ43/i8b3/s3YPdccvkXqtdkNkalL4LDfu5naTieZyRRYPO8t3+fFTWDV9oHyQ0+TbW6m4PxOxld+AFuW1x36vl+JypoBTqjnbRGWin3zhw3aYbJG8cPsc58jrLyKjKWh9a+1+jqjLBp3V30nfgWg/FRpj2f5lObNvMf+8c5HP06jd2PUrv2zy9tH/02TNPipc5JOsZmGkpe6pjkgZU1aKaGy+5iOF6gbSjJsrogY8kiTxwa5aMbG6kMvP337tU2nSnxk7YRjkR3oto6GcjOI56/lftWNLOiPnze+2iGyX/sGaTM5+SupTWEfZd+3P+momZwZDjJ4eEkedWgIeLloTX1eF1Xduz4VqZl8lz3c0znZxqL6oMX/654q/5oHo/doD77IiQPA9AYXEzEtpCeqdA53wNnOjqawpbrZ77vDZ6OZtBMk+XT/84C390cG78Nn8vO1kVVuBzv3M/jpZrzYQawGeixLKsPQFGUx4CHgXdPmGFZ9Pe9Sm/H94mlTpI3TYJ2Nx57ALfdT8JeRm9kM/OX3E5rfesvNNRI5DIcHtzH8GQHjdVLuHXJHbgdMzvZnJrjJ53PsqfjRRQ1h+EJ4wqUs6ymhfpgHSF3iKA7SMgdoiXcck7IoRoq32/7DqP9r+JVkwT1NB5ULGyYoVWsWPpxNiy+E5v96uzYrpVErsTuvgm6J7PopkJNyEOuVORnxwcpGlm8LoPVtYtpraikOuimMuA+a+eVKcQY7vtP8mMvEctMghnE51xO0rWGysgmXu+JYlrW257ETaSKPH6gh8PT21Bw0lz5QdY3nd5p64bJS+0TZNU8KBYDU0m8Zpz60jYqlSMcd/gZsi+h2tVJfepZDh5fwdb1t17wMY8mC+w8MUUiOUGjJ0F1xMNIsZy2QQ+qoeGyO5lfHWBZXYjWCv+lH9jnhunoeIrdeYPb1z3IbU138q2f7uRk/3PULPnEVTlQPFPneBpH9hkSnT/FY4Xptf02Y6la7MUjZAsp7IH3URM8t8z3zN/Ay4fW0ze9kwXRAwSrb7qk8gytyNHd/0ox1kGpdi0dFNAtg4cWP3Tqc+11elmz4D6ibW0MDuxgSeUqClqBI5NHKGgFNtRt5LUTGYbied67tJrVZx7AmwbZ+FFO9v+EWLyTTGglzrK1+INuDg6HuHl+ORUXOEja0xvDboOPb2ziRwdHeLVrio9ubDzvPseyLF460c3R6I/5WKuT1Q4dr26QVw3SuaMMpObxomMziqeSX97cTNh74YMdy7IYTI7zTNsEFVaCD1RncA1uY5UrzOKFIfaPWRw7OYbXvpSlDRFGM6NohobT7sRpc+J1eqnwVvxc+0fTMjkwdoD2qXacdicuuwu33Y1NsYGawJMfIDPVRXVslK01tWysXE9wqANFvfn82zNM8iNfxyhNUL/qT6kLN1EXbiIZ/SCxoR/T2/N9Fiz61YvWq3fwOVLpfnzNHz7n8bnsLpzeBgrZIe5cX8V4ssAL7RN84uaWc07O2k8cJFPsx1+3gf2TBi+Mj/Op8DPYvHXgnQm6euO99CX6WFi+kJZIy8xjP0NRM3A7bGfXwzJRU70cPLKdTGoKzbcAf/VK6qqbaam4/GCzL5o71er1Yvsk719dd6q8oyNJtve/QdroZqqwlrVNkXOCG9MyKeklPA4PRc3kZ0e2s4Iu5jU9BOEVMyt565i36EMs3PcILx19ik9u/cRF63VyPEN8+A12jXgZa1nCLUtacNhtFFSDlzsn6Zm9ZN9ANMeDq+sIeS7/AP9NeVXn5GSWjvEYx8e7yKWfZ6N1EDNwKy/k3o+e9xJy/Bo+9W9I9HyJnYkvkMir3LW0imhhGr/Tf2qiWCyL7qPfJJ45gdX6S9yx8EEizhoObv/vbH/1D7j/gW/h9USuuK4w874YSeRRdYtyv4uIz4lm5plMmbQNpRlJFHA5bIQ8DlwOG26Hjf5oloPDUdY0hsiUMrx+9KsssbvJKh9iVUOYTfNu55Ed+zg6sZ/3TLyCs+nhc8odSxZ45ugEpmWRKWrctrDykvYBM8Pzpjg522Ph8HCSTa3lrG2K4LTbwNTIpweYnu7B5wsTDjfj9Naw78C/0zPyHKOhjfzu7X+Ez+nj755P0zn+Cp5Dj7By4x9e8clvUVXZ3vECHd1PY+X7ILKcX7nzz6kNnQ6hpzJFnj4yhqqbjCULvG913Tmfr7Fkgd1tu/HFf4ifExR8EQK5x0i1H+aZ2CfZum4zZT7nZe8rM0WN4Vie+dWBs8vUMkQn9tM3+AZ2dzWh8k3Yg6143S6qg56fO9hLFQqMpKIsqao7b7gDYJgGB8YO8NrAaxT0AgoKq2tWs7VlK719Y5RNf4dssMAj0y50JUerOU1tz78xHkoz1P8U3doCNi27nyU1QX5n68P8/dOvUtf9Kg+0PIStfPUV1dswLX52dJA9Ax3UhSfJqVN843Can/VDTdhJ0BUhk1pMS2gpdy2rIV8y+OGBYZ44NMJHNzTht6vExw+TnzqMWUrgDFRTcLqYVix0ZxlB30KcSj3JvEl92MOCqsDbhpnno+omQ/Eczx4boT3xMtX+QW6K+OlOt3Mi3sv0/vdy9+L1vHdp9Tnvlf5ojnRBI1fS+e4bA2xZUMm6psip8md67HLe+liWxZ7eGG3DSVTdZF6ln8YyL3t6Y/xg3xAfXNdA+SU2AuqGSTSrUhNyn1VH0zJ5svNJjk0dw+Pw8G8H/42N9Rt577z34nV6SeWLnBhuZ3SqE5sXVI+dyXyMglZgVc0qbmq4iYgnwsTUMDdbzzAyOMh+zY2pOFideIHVpW2MD23AWPBR7N6qc+qlGSZtfaMs1p+gPTtIvOJeVtSsJt73XfyJJ0iVjvLDY1sYiN3BAysbqI940QyTrvEMbcMJLAt+9aZGBlODdEY7CbvDbG3Zesmv7VyjzPVuKoqifAS437Ks35z9+5PATZZl/d751t+4caN14MCBX2QVf26PP/+nGGqWmVdq5l+F06+bUpxELwyTVvwUK2+jrn49ieIYhewAbiOLJzeOPz+FHSeauwGb+/xJ6dWkYFEoTKIUJ3BgoCgKlmWhOUNU1W2mpmYpB7qew50dpc5dTnO4iWguRUrLMWEqFG0WJhpOm4LNbsdWtYYHVv8aLZGZSwrm1BzfP/o9jO4naLH5cfvqcASa8IYbGY+fID2xA8soYLpqcPobz6nd6X/PX/sLPbILP3DlvMchdpuLLRs/R2P14rOW51WVLz31eVz5IwQ9TsJeJ97ZL3nVMMmVdHIlgwndj+baQGVwK2FPOcsb7ERsx5mefh1bog2HUWLIqGNfcSl5dZDfmb+EtcE8DoeTE3E7wymLluoywhEXlc3vw+GbObgZSeT5zt5DdMV/xtbIJJ0JkwGzit+/9SFub711JjA6tIvXT27j9mA3tY4iflQwHRRMjYHAUlpbP8DtLbfzSt+LxI48QohaNt35DzRUnbuDBjjYvo/h7meotqdZUOamOuhGMzWi+SijhSQ9eZWU6sQywnjsZUTcZdRGLBzOLLFCjLyWJ+gKzgRdriBhd4Aylx+vzc5EdIBnTr5OT+U9/NV9f4TD5uD/PPXPLMs/yh1b/5KqpvtOVyR5DDLdp/7UTB2Htx4lvBzcF+7JAlDSVL7+kz+hXt9LZc1SzMIEfbEcSsvvsMLfS2/nM3iXfYMPbVx23vtVhqbuAAAgAElEQVT/9MgJJo98jiXNS7ntjq9e+MBQTZAefYX9R3/MVHqUHv8CjPJm/E4/d82/i/V1Z7eMZ0s5/uHxT7A5oFNRv5LB1CCGaaApDtozfnLcxK9ufB83zasFLYuV6SWfOMbI6DYmU4Noio1IoBGbmmDE8tKmNPPGaInPbfwtHl618rxVnMoUefSNIepCfXjyT+Ot+Bgdk/Xcu6LmvK0zewZ6+dprX+aj4T4iLosoXorhVSxuvp8adRBP4iiFksaBZDP2ipt5cPNN2N6mRXAsNcju9u8w1L+XciNOY8hN0BsGTw1+xcSLhlNx0BdNMp1P4PTZMdxBdOX0yaIF1JQv55ZFD+P2N4EjCHoWtBSWmsTUcihmkZFkL32xThwOH/Xly2gsX47LU85grJP9A9soFCapcvuwK3Y0U8MwdTx6hqCZo6hBX85NOLiQD63cgM3S+P7rX8Wo+zCfvPuPz3lcjzz1TZqL3yA0/33csfHPTr1HDENn587fRcn24Spfe2p9xRlk0bLfoiJw+uSlL95L+xt/SKXLw4b3fBuX49xwbcehL2Mbe4FVS36F4VSU3X1DeIL1/PLdf4LTOXPwnyvpPPfcFygVtrN469/SFyvw6IHH+cI8i7V1S7D8LXREOzk6cYySbuByKPidPppCjUTcAWLpBNPJBLlCFo/bz4LaRsrCNTgdHvLRI3SPDREtFVA8XvxGhpJmkbYC5BxVzKuqZUF1HUFPGUGXH5/dgWLqFEolfG4XOpBSc+T1EoppsL8/it0yaS4PMDCts7K+goXVfvqm+3ih83WctiwtYS+98Rz1oRU8tOpmbA4v2D1MFJJsH9nLVCZFoahjlmyErCgtPo373/cYdk/l6SfOUHniyY+QKJawV9yN5W4ETzOrGxayoaXmnOf52V3bqE89jddlMJiIkbcrmD4/Y6kSumlRF/bicYfoTtdg867goXVbWFRbdur+umEyliwyOj3F4NhBppLtrFnyAFuXbTzrJKBjYIA3jvwALd+OyxqnzKkScbtY2Hg71Sv+CJvThwLYbQpDAz+l/9g/kFGa6cuAw5GlIuDAsntYWH8za5rvwq7G+dm2v+CQWcsff/hrBNwzrYk/3PFj1IG/o6KqEY+/FrvNgcPmoDHUQHP43N6RJb1EV6wLEyc4fGQ1F8kCZHMlikUVl2WgmzmyeoysFkcz81iWQthTxqKKOhZX1VI08iSKSRLFBMcmE7SrFcxrrsehKNxcaKMpsImXSh/j12+dT9Dj4JEdb5Ac/Gt+qaWCxfM/cFZQUNINdp6MoihQGXAzFM8zv8rP8roQirscvI3gawSHF8tQicaOMDG1n2hsgPGEgoMwaxvrqQl6aBudYCA+iUEKnzWNTZ1EM0qnuoLbFAWH3Y5uGCS8S/nUQ48Q8syERelinkee+h/M146wdOF7aIjMo8JXgU2xg78ZQsvAcTpws0pxxka2MzbVSa5UIq+WyJYKZFPtOI00XqefQGAeidQJkp4qVm38fW5pvZO8avLDvT2Uq12sqFTZN+7BEWzm/vXLCHmcTMdG6OrtJDN9DEfxdTLOAvmaO7h58Yc5dPLHOMZfwaU6MDw3UzBNVCuHbmXQzZnhjG9elampPERzWRk+hw+P3UWpFCOfn6Z3YgRVLWDYA3h9FVSWVWGpCVLxbtLFPDnLhRsdt82Jx1mF5lqGwxmiJuSlPuyjzO8kp+bJlApkSnkM08Bld+N2eHDZ3bhcflyeCG53GMPupm3wOF3jx5lOD+AwVQIeJ4sqa6gLVeJ3BrDbbNgUG5Zl0R3rJqNmqAnUsLxqOWOZMbrj3aQKKp5MAssJsYb3sLbpdoKuILv6X0frfpqFnjwaTobCX+Azd2wh4ps5iX68bQeTRz7P1sblrF38XopGkUwpg2lZlHvLcNlnT7ZDyyF89tA/gOGJw7y4+/8jlxmi0WdQ5XUQcAWI5RSiJR+tdU10RYdIZidZWRlmVWUzAU85OcPFwVEVwzTwaAPoRoGE5WDSUHDqYwQp4LApwMwwPBU3irMSlBBul4+6sjIayiJ4HR5sigMFJ6puEC+kSRQyJAtpsoaLnNJKjgUY9iqS2cdZ5+vh1kg5jaEGsmqWzukuBtIZskYdWxYsZ0FlCy6nH7ChmTrbTnQzlplgYY2XoViOZEHF63LgcXjAcmKZLpyuMBvXPUhz7RKcdieGaTCVm+K19r2MD7xKS8jPxtblNJfXo9jdTKfTvNR+lHhxgApfHp/Lj1Px4VB8eOxeAm43AY+LgMvFeCZBX2yCkfQkWS1DTe063n/Tp6mPLMAwDX7c+WP6Jw/wQFUzS4OVtE+10xU9QaYATt3AXppEsVQUZWZKNr/bT0VZE85ABSOZcSzLosxdTXZyGLsrw2B4BZGqjThtToZiXYSSXQRSQyyoqKK2ZiXl9e8lUnvbqQa3PT1R+o78PZW2PUzVPciHN/wePqcPDJVM11cYmT7CzzJuOnPzWBS5j1X19QzHC6ilNEHtdfKZI5QFszjsJnabncbqjdy87g/OeZ/d6BRFOWhZ1saLrvcOCDM+Ctz3ljBjs2VZv3/GOp8FPgvQ3Ny8YXBw8LrU9Up974cfxtJn0n/rrJPp2YMXm5tgw93ctvZXqA6ebn03TIPJ3CTTuWmi6SEmh/agRdvBvDqXVbvYO8fhihApW0xz7WoW1K/iSO8+evu3oRROoqDjsEeoq72H9SvvIhBuwMiPE5vqIx4doFBIU9R0cmoRXY+SMUboqVzH2uY72VC/gcePP45j+gCLCjr1K/4ry5efnTgWihl2H3mc0cHnsfRLm/zr7R6PcpFHal30mQCbnsPu9HHPvf9E9eyYdcuy+NqznycQe57lDSuI+MNYgGWZOGwzO3WPw4PNMhhPnGQ0PU7KcJC1KtGzQ3hsBtXBML7IStrVO8nalrCqMcDB2A8o94b5zPKHUeKHsLQUx4cmODyyD49tkIDDTim4EbP8Q+wdGYfsj7m/LMPGmiUUVfj6QIkel4cV9bXE81mGhwb4cHCKNfVN5N01pPGSwIXpreeW+fed6oppWiZPtn2dYvt38Efu4KEHv4j9jJPPolZgd9u/M3HicQyHEyVcQ94ZwfDUktdyBPQUDQ6LBR4vqpYnWoiSzOdIFTSKmknQ42ZBZTUht5+CViCrZinqRSxFQceOaroYSZt0Us1ffuAL1AVnTiZeOD5If9tnWN3Ywi13fmOmMrH9pHqeJKZZGPYc0dw0qWKcGpeHFVUrcPkbIbwMytaD6+wTccM0GEsNsm/P/yY/3Un9vAe487b/SSE7xCsv/yHR7BSVYT+TuQo2bf0qa5rO32I5HM/zk21/y0LbNooLfwOXtwbH7MmAz+kjZFMI61Fs6S6mJ3fTE52kqxgi0HAHNy17D/PL5lPlq3rbEOQfX/hX3FOP0VzmpylUT3O4mbFojK7JLhRHFneoljJ3AFtxipJRomgpxJ1VVNbdzvqFH6HMVwGxfVgT2yjqBf7fkxN06fV866N/jsd57gnxT9pG2TO0iy2271JOHg0bg84PoXnu49O3zjurJW40PcoXf/bX3EYnD628G8+CT3EsHWXPyB6mclMAuEyVZnWQUHaYUslBU9UiVi59H4HIUizLQDdU8mqKE/3PEJ/cRzav4XS0Ulm/HCNSw5jpJlHKkNNyFNQsLjOPzyhSSOpU4OC9LWWUux0YloFhGqSKCUZi7bjtLhaXL8NtD5AuamSKOol8gWRxmpQ2SckysDv8BJ0GAaeO3WbD5/SRU3N4nV7mVyyhMtSKckaPBMsR4Fi6jl1TlUQiNTy0po6gxwlamscef4BC9QP8+r1/cdbzaVkWjzz2WRpcg7z/4afPCSEyuQkO7/tzTPX0EBVFTTDqaqBq0ae5veV2pnJTPHXwH9lc6mDVuj/FU3P+lpkjAy8z0v5/sc1eVSFbVCnmMqhVv8rH7/pdAm4HOzsHmWr7rxTKa/n4PV9Hwc7v/eRfsIpH+asVjQwn+xhNjaOqYSLOeeT0JEUjRslKkNdMcoYNw+bE5/WRL+RxWyp1Pgi74FjGQ49eRWPzGhZW16NoGXyFYezpQVLJSfKlDF67SblvJljJagoF3YVpuQl6DYIuHRsmNixSJZPpnE5F0IvH5SCaKZHXoCkSZDSTRSPIA8tvpbm8lee7XqVzvJtN9fO5tXExPdPtjCb7yRXAqVRgouFwKThcNuoXfoTlS87tBXP45PO0H/xbXFYRy5o5QRi2avkv9/8LC6sbTq0XzRTZ/fL/QqedweAiyMUxUjEqbAoep526sAe3w4appckXM8TyKlndgdfbRIV3IXZ7BN0ErxGlWOolo48AFiXdxO5bxE1rfonKUD07D3yPTHw/ik3HH6mnvnIJdeXLqC5bir1sNdjP7Vn12sEvk5t4FVV1UCj6aI5UEvHEiWbGcNld2PGzczrDkk1/xUMrtpy6X6qg8b0X/50abRseh4Vm6qiGimGpbKxfx6LKplP7J1XX2Dm0h3guiaFr6OrM86Uo4LLbcDid2J1usNmxLBs+RwSXEsTpMFHsOdKlNNbs+9Pn9BP2hHDqBoPRLL6KBdTUL6Yx18VLqTuwVazng+tmnvupTJEvPPMIG5UXWVJRgW7p6IaOYZlMpEqoukVTuR+v00E0q5HM6VQG3DQHLOyKDQUF1e4jnR0jXchT1AySugdTMakKuvE5XdhttpmhrrpBpmBiOMrB24w3NB9/eD5qKUsxO46Wn8au2Hj/HX9AWSB01mvQOxXnmZf/iCD9RHxOgm4PVZ4IIbuCy+5BCS6g6KpheHg3ydgJMmqerOnGZKYBxWl34PU3sHTB+1i39P0oDh9vHHiC8Z5vUHBo6PW3kRyfpFbrpzGkYHPYyBeLTGUKFLHjcYClmzhtDlweD9O+Wurmf5j7Fj2Iw+bAtEx2D2ynu/NbePNjmKaFaVnYFTcOmwsFBZsCJd0kp5aoDCq4HTNHT5rNxUTeQazop6WyArWQIJuLYTeyGIqbvHsJlbU3sWHhZgraFMNjO8nFD+NXYxRVjbxqXnTOJgVwKToz0eZpXqeH6lADfk8l/fEYeT2Ly1nC4wTVMFB1C9UwCDgDLK9exoKKOjwOO9PZEr3TSYZTg+QUlWWbPseGljtO9RC2LIvv73+DdN83UF2r2LzmE2xZcPr42zRN/tdT/5O69BuUex0EPOCwnf5OCLgDlDl91HkjVCz4VajcfOq27uHXOPbG/yZbhIbataxsWUNl2WLsdjd6Icaerm60fBzTNPEFDZJMEFfz2DBwmSqWViSTLxF3lJP01uLyV1ETrKHS20SASjyqgVNPYLNGMPRhCoURErkkiWwWTS1hV8yzDojPPO9w2R347SouxcBht6HYHYScdpbVrae66QGIrAEjj5Ef4+jgNl7reB2/06A+5KLcE8KGRTSfYDieo8znpiY4E4zmSgaJvIpuadgVE7vNhqXmsWFCpIFkcCklyyCc6saZGsXvceP3eXBg4Lc7CXvCJAoJ0prGdB4gjGaqqGYByzJmX7Oz3zNOu52qQBkuHCSzw5QHXPjLl1F0lFFKHmNtuJbGUCOWK8JURuX42ARjuT5weQhG5lNXvZSG6mWkEkUGRgaxFSeocuewKRqx4ijj2REmSnbmr/0EWxfeQ01g5phUN3V6Yv18+/VtOHP7WB8Yo0wp4na4URw+EiUHo2mDctsE7uY7uOumz8+EPG/SMjDwPaZjxzka7eZYoZyi/RaanT1UGe3YFJ2+lI3W8gZW17VQ6avEHlwIjQ9d8DN0I3o3hRlbgL+0LOu+2b//DMCyrL853/pzsWfGO4lhWhwfGqVv9DhrF25mXs2FW8Aty+JoXx/JY4/g8GV41VmLrjiopsCGTIy0awPvuftzM906b2CHevbStvv/Iex2cs89XyFcvozndv0d0d4fUlO3lXvv/luwXWDUl5okFz9K7/BLpFN9mJ5FjJaWM60vwbB5qQi4uGd5DXVhL23jbTx14ik+tuJjLK9aDkD7VDt/u/1bePV6ltBNlXYYA7AcLtZUlLFi/oO4Gx6E2H56T77OnnSETH0dxakoG4w+blq0FPfCT1+0x4Ju6jz2yp/B2A7s4dVUtWzEHlqIapSI9f4Apk+Scy1m3Zbfw7BBTsuRVbMEXAGWVy2nxl9z6uDXsixihRjjmXGmkm46RsBut3HLgkoWVgcIuB2ohspIaoLnO9s5ONKPTpJf33Qv75l/et83GMvx41e+zDLbNlZv/SfKyTHR+e88PZLm+WItTqeDdfXz2dy8iOMjuwgXk6xy1eIqxGgu91PduI4JzzzaswniscNYiWOUaePkcyVivo/waw/+3qnQZnBshAO7/ieK0U3M8xE+et/vnGqpeSvTtPjGq23MT/8ldq9CTvFQwo5qKQSMJAFj5jrkJcVFp1bPsHEL96+8h3uWXdr49LbhKI8d2kuFpxm33YPXZSNfLHFTTZ5FwV76hrdRMHUMXwtKcCHuQAvLqlZQ5i07e0NqCkZ+Qu/QPv64T+felbfzuU2/claIMhzP8cWXf8RK29PcEbGxYOV/o63ru2QTJxjW1tG67L/z3pWtlIwSA8kBfrz3X2mJH+aWBXcyf9P/AGfo1Gs+lZsJVzRDm+mxkxljV9tPsaePszpcwu90YVjGqRbPtG5jzFiNN/wgd66/hebKc8egWpZFUS/isDkoavD4/mEA1jWXkSqoJHIaqYLGRKaf7qkn8ZpRWr2NpE3IUKRkN7GcHkLuBhZGNhB2tTKaKKAZo1T4BvA5J1lSs4Z1TXdgd/phtieaapjkSwbbT07TH82xoj7Ee5dWnx5zruf40eMPkii7jc8++Ndnf5YMk39+/Ndo9WV5+INPXNJrXhh6ksGex3nBrEH3NaOZGuuL7dxRsxT3ij8B2/mHLZT0EntH9xLxRKjx11DhLeeFFz9LPHqSTM1fcveam9mz/4cEM9+gZsMfcevi/wLA/oEJvrj9n2itZqaVs7SG1uBati6qIq/qRLMq4+k0TrvOuqZqltWV47TbSRWKPHu8j87JKQyrRMAZ4eMbljO/6tw5DWbm1knzfEcf0ew0eT2LSpaAt0RRz5HKudgyr5WtC+bjsQd4/MAgAbeN+1dWU9SLxPJJfnqsh+lckjJXA791890sr58JGE3T5C+e+z7HovvY1FJNqlhEz89nfmA9ty+uZXlDJW7nxUfjmpZJIT9FIdNPcrqNA4cf5YRvDf/twb8+9Xl6du+zJE/+FXrDzaxc9kkagg247REGowWW14dOf4dZJrlMP+NThzjes4+JVBc2S6PWV01TsIFhNc64pVFdvY5bWu9lX/sTjA68TMDKYLfZyRh2HJXruW39p1lUu/6ShgK8OazG6/SyuzfK3r44Ea8DwxhgOP4S6fQAVmAj//ChPzin2/frPVH29c9MRuu0K9gUk13jPyFeHGVL3UNsblxJplTk6e7HiBbGWV/5fuaXLaS5zEN92KAqADank9JsEOJz+qj2V58zPEk3dWL5GBFP5NRQVfQ8u/a9gBLby+ZGFynNzqPJj/D+dS0sqDq9H3ixY4DvHP4RVUEXjeEQDZEgQ/ESJyZSrGoM0FDmQTd1dFOnfSzBQCyL26ZRTpIKkoTIUqAGy72CUNkGltW3srzBwXR+jJH0CJqp0RhqpDHUSKWv8py6X6rDw0m2nxxlLDuAYRvD5ZqG0gSR0gRV2iQuvUDcCpL3rqSh8S7WzltPTTBEmdd33uETlmWx6/ABkj1fxdAHUQ3wVC3EqlyF7qkhYBVR8jFGhwfQLQVPWTXe8ipKNg/r6tefOn4403RumoHkAJW+SmoCNTOtxWco6QaP7x8mW9T5wLpynA6NaMbGi8cTrGuO8J4l1cDMEIU3h1UtrA6cM+6/qBcZSg2hGiolXWMkmSOZ14i4g5T7w1R4Q7gcDgp6nryWJ6dmKeoahVIerZTF0vKsbFjGisal2GbfL3lVZ1d3lOOjKQxLw7RMHHaTcr8DVfOQV2fCMo/TTlEzKPe72DyvnCU1wfMOd0jmVb6ze5Cgx8Ent7Sccxw6kBjl3/Y9TTRtx+8sZ11DE/URDx2TA3RNDzCSGuRu9wlur3TRuOiTlDd/kLaeJ5ju+Bcmcl4qlnyB92/ccE656aLGD/YOEfI6+djGJhTFojfeS0EvnHrdbYqNiCdCubccn9N3SfsBy7IYTmToGI+iW0VQVExKuB0KDaFKmiI1hL1+TEMjkTxBPH6cfKafhppNVNa957zHsK90TbCj9ySbF6mMZvqxsNDVKsaiIX7/jpupCfnPqUNRL5JRM4zGhjl46Hnq9XZaykywbIykXBih/7+9O4+Tqr7z/f/6nFO90ew7dLMKLmw2ikjiEhdEXDFGR6M3+pg40Tgx4zXJXM3k8Ut83EzuZNW53jgxZnTUTCIaY6JOjI67iYEoIiKIaIMIzdo0TTfQWy2f3x91Ghqoqm7ohuqG9/PxqAdV33PqnO9pj6dOferz/Xw/zezT/4bmIOTDmg9ZufUD1tetYVT/cUwbXsHYfhPYUh+npDCktDAkRSM7mneyrbGB7Q2NbGtoYGTfwVSMHENBLEZTS4LH//xnUjteYlThUsJ4HWNGnsG4sRexLTaBl1c1sW5bA8P6FnPO8UMZ3m//H3MSyRRL19exctMOEiknmUzRkkwwvF8hl544JuPfu64hzuOL1rGrZTszytaR2rGU2voa1mzZyoCCOOPLj2HmKd/OmE2JO+z6hB2bXuWDVU+ys7kOgiIKB53M8DEX8db6cpIp49pTM++7pziaghkx4EPgXGA98BZwjbsvz7S+ghk9TyrlPPOXNyjb/gRlo0ezMBjGSfUrWF0NQ0/6ByaPGprvLnbIS+/9hVXvfIuRpYWMGHUmH6x8mmTvk7j24nsICw58bHRrwbhdLQmmj+q/+wtSylPct+g+kqkkf3/K31PfXM99i+5jUK9BfO64L1AYi2HxLVSv/jVBciejJlxD0OdYWvPlmqpe4L13/oum2DBiLZsZVTaB8uk3QKy0nR6lNcUb+O2L38a3LqFXrJni0hISYRHFjU514WzmnPVlhvQ98NoV2xtaeOH9zVTVpj+wB5YWUj6ghE9qGqhvilMxqj+nTRi83w1FMuX8/KVFlNf+I8X9hlDUspXlu0p4IzmLSyafQcOuodQ1FNC7KMaWhg28uem/sCDOGcM+TXH924yPLaEkbCAZFDCgoITeJQOI9Z3KSxsnM2H8yZx93J7zL5VyHnp9GX13vsWuvqdy3RmTct5EPL98EzvWv8Hlx8YJkrsgsQtPNBAvHExD8Qh2FA7lrY3Gx1tKOWnMIM46Nnsmxr6SKeeTml3saEqwszn96FtcwKzxAw+8LkRLLYkV/5f7KpP8NdXIraddzYyR6c+XzTs386NXnsZrX+Tvyo3jJt1IMPwcksk4f178A2pW/5GWeG+aC4qxXoWkCkrovX09g/vM5IzZ3yQs6tvOztPj03/+p6XUNS5j1qgUbgXsag6o3gE1jWOZMKSMC6YOT2c7dMCWHU38ZlG6MnxRQcCAXoX0LymguDDEaGHhpv9m/Y6PKO8/hPEDRjGizwjG9R9HWd89v7RvqW9iweoaVlfvorggpLQoxD39/2Ui5TTFk8ST6c/XMDA+c+yQveuTACSbefKxC9jc52RuvuRHe/WxOZHkvvnXMqEfXHTJ/A4dF6k4fPRztjdW89v4UJJN1VxX2kRx+cUw9PSObSOyY+cGFrz8RdbvKmLbwO8ypPaH9CutY/b58yktTF8LEskUd7/8V1Zs/xOjes1gXP9xzKso61DRYndn5eYdvLtuO6dPHEJZ/5Kc68eTKZZvqKdXYcjYQaUUxgJSKef55Zv4YNMOzj5+KE3xJAtW1XDVKaMY2WZ7tbtamP/WOsYPKeX8ycP32u7GukZ+9PIfaeJjhhbOYEz/0Vw0bQRDM9S66RBPsfjVO1m87k/UjLmAL596EzUNtTz1h5sZVZTivIt/Rb9eg9vfTqQx3siCqgUsrFpIS7KFgqCAuRPmctKIPYGKmp31zF/4ODsatnDhyX/DtLIJB9d3WmewqGPttnQWQmM8ycad67hkymQmjdg/mN0atCsIgt1f+LY3NHDPwn9nVc16ju07l6pd79KQWs/njr+CM8dPp1/JgddbyGbrzmZ+tWAVpw/ZQnVjjKrESL542ri9vnzGkykWrKrhoy07qW/cM4PN1LJ+zJ6093Agd+e99XVs3dlMIpnOtEk5DO9XxJhBpQwqLTykdcdaEine31jP25/UUt+Y/sKd8kZKi+MM7hVn5vipjBnYp8N9cHdefO9jtlS9y+TjT6Ji/P5fbuLJFAZdVthze0MLj765jtKikAunjuA3i6roWxLjqhmjukXx0C31TdQ2xBnSp4j+JQUEQTr4XLOrhU9qGthS38T4Ib2ZOLT9GhKrqnfSv6QgZy2p+qY4i9ZsY9n6+nRR58AY3q+Y4hi8vOrPTAmfYkKwiVTfY2HHR9TFh7Gx99f5wpkVWT/TmuJJwsC6/Q952xtaeOgva5g5biCfPiZ93fvPhZ8QmHHNqe0X6t9c38STi1YzxlaS8hSbwxP4m1MndvizvqPW1jTw28VVTCsrpWKUMbD3CN5Zt503PtpKGBqnHTOYqWX9DqimSEds3dnMbxZVUVwQcMbEITy3bCMDSgu54uTyvQpX55JoqWdz9WKGDJlBYWE6iLtozTb+9NFW/u6McV3+tzqcjppgBoCZXQj8KxACD7r797Ktq2BGz7S5vomX3niWTxX9hTHDh7F0zUY+LL2SK86Y1eUXl0PF3fntW3+mesV36B/uYnM4iesuvpeBffafNaCzVm5dyaPLHuWCCRewdPNSahpruOnkm/b/1T2LD99/mZoPf4/1mcipn7kRix14ZewPNmzj7fcWUsYHjCzaxpsNMzhx2tlMLT/4mi3uTvWOZtbVNrBuWyPrtzdSWhgye9Iwygdk/zv+YelGdq26i/LCd0mVTuKVnYFbiM0AACAASURBVJ/j3ONP4NMTBuPurN3WwJJ12ykuCCkfCH9e/zTr69dTWb0Ti/fl6lGDOH/0YAoHTCZVOpF3NjTw+odb+fzM0ftF6V/7sJrFn9Qypawf503af9x8W6uqd/L0kg1cNr2McYP3BIt2Nieo3LKTjzbvoKq2kRNG9OX8ycMO6U10uz7+T1Z8XMkPtvRi/PBmPjVqFh/WfMjSjWtp2raJW0ck0unNY67ePS7d3fnzyt/w0UfPkdrVzKDAGNu7iK3xkYys+DKTx5S1s9M91m1L32wUhMHu6eligXFiFMQ60CJxTfEkKXdKCsKMf9dEKkEsV7ZUZGNdI++uqyORSmFRyndgRq/CkF6FISWFIcP7Fme+2U0leOqxC1hbcjxfvez/7bWosSXJ/Y9fybEDenPBRY90/MAaqmDVA3j/E/FUE8HONXD8bRmHF7Rn9Sd/ZM2S77PVjqdX8/v0P+YyTj/p63ut8/Yn23j9w62UD0hXkj/YWYgOVrpI3gZWV+8iFhhjB5dmnKGkJZGiILSM/63/+N5GPti0g2OG9mbOpGGdPoad2yp5+5X/w19TLRSNOoVtNWuZVLuIk6ffxoTJlx3UNne17OLdze9y/ODjdw/t684a4g38xzv/QXVDNQCXHnfpfrV9uspzyzbx4eYdJFPOp48ZxKlZil27O1t3trC6eie7WhKcOXFIt/hynUkq5VTVNlJSGDKwtLBTRTBTKae2oYWBhzgQ09a6bQ08uXg9Zulg7jUzR3d8ZrYj1I6mOPVNCYb1KSIWBtGsSxtYXb2NU/r8Dt/6KgWlk3gz/nd86tjR7c5C11M8tWQ9m+qauOH0cdQ2xPnPhZ9w1nFDmD66Y/ej67Y18Pt31uPAFSeX7xWo7kqvrNzCkrXbmTN5GO9vSBcdHj+klHNPGEbvokM3X8bGukaeXLyelkSK/r3S2Talndxfzc5mHlnwCeeeMJRp5Z0rzpxPR1Uw40AomNFzvbpyC7WVz1BR8gFvNk1n+smXcOyw9qfD606SKec//vQn1m56hcs/dTMVow9NVom789CSh1hbtxbH9xpy0hGplLN0zTrGjxhO35KDvwHZWNfIM+9uYFdzkuOG9+GCKcO79GYqlUqPuW5vmys21vPa0uVcccw2/rBpIkkKMqaFtoon46zYuoJhvYazdJ2zbH0d44eU0pxIsaW+iXjSGdKniGtPHb3fvqt3NPPrv67lkhNHMH5I9mm3IP3L9s9fX01LIkVhLKBXYUgsDKjZ2Yw7DOpdyHHD+nDK2IH5D9rVrWD7B7/ksa2n8nHBckoK4wwoHsnGjSVcVfouJ44Zg034UtYvzTubE7z+YTWVG2voVVzC354+/oBv0Jes286muiaG9ytmRL9iBvcu6tIpLA87T/Ffj1/IqoLR3Hr5/Xst2tWc4BePfZbJQ4dz3txfHNh2N70MW15PPx96Bgw/96C7+NZbd7Jr46u4GVM/8xCD++79y24q5ayp2cWYA5l1qIslkimeWrKB9dsb+R+zxnS4kn2r5kSS9bWNjBtc2mXXp/cW/ILqjW+yoN9QBtWu4cTCQZw69/sEhV0fvO6u6pvr+c3y3zB12FRmls1s/w0Hqa4hzsML1uAOf3fGuE5/EZCusbRqOy9/sIW5U4Zz/PD2M/CORg0tCf5z4SeUxAKunJziieUpWlIxrvvUmG4baDtQn9Ts4snF65k7ZTjVO5p5Z+12bjxz/AFNobqxrpFE0jNOGd5V4skUv1r4CbUNcQpjAZ85dgiTR/Y9LAHAtTUNLPpk20FPU7svd+c/3ljDoN6FzKvo+I9G3Y2CGVkomNFzNSeS/PIva0g1bKB3/9F8PsMXyZ6gOZFkc10zowaWHNL+V9VX8cDiB5gxcgYXHXvRIdtPe+qb4ry/oZ7po/t3OG2uqzXFk/z8tdWUFoXsaErw2elljB3csWEz7s4blTW8W7WdQaWF0RfpkpxTRja2JDv8Qb1+eyMbtjfS0JKkoTlBUyLJ8L4lHDusd87U1cMulST1wV28uraA6sEXcd6kYTyzZBtl9X/gzOFbKTz+76E48ww2bVXVNlAUCxnSpxsdWx49+5tLeZ8BfOPKh/dqr2+K88BjF1MxciJnn/fTA9toKgmrfgHNNXD8/+zwELFMEolGFrx+EwW9ypg1K2Mpqm4hmXIaWhLdJqW2rq6a5a/+H8I+I0jWr6Vv+ZlMmfE3+e7WEevtT2qJJ1NZpyCX/GhOJPP2ud9TtH7ZH1hayLZdLVxy4kgmDM39Q0hP4u48suATCsKAXc0JhvUr5tIM2XPdwZYdTSxdV8cp4wa2Ox18d/fKyi0sq6rjy2cd0+2HI2XT0WCGwtfSYxTFQs4+YRjPLXPOOIDaAd1NUSxk9KBD/+tced9ybp11K/0Ow1S8uaTrNOT3BrO4IGRE/2LW1zZy7LA+HQ5kQDrr4/SJgzltwqAOn3MH8otDWf+SdusFdAtBSDDwJMZveZ6V23awoLI31H/AKQM2UDhiTocCGUDO4UBHIwsK8ETzfu2JZBI8TnAQw0MIQhh3XXpq2U4EMgBisRJOP+uhTm3jcAgD6zaBDIB+/YZQOPx04htfBULKJpyT7y4d0U4e07GUdTm8FMho35hBpZw8ZgBvf1LLmEG9OGZI567Z3Y2ZUTGqPy9/kJ6p7OwR3TejemifYmZPOsh6Sd3M+MGlLFm7nXXbGtrNEu7pemaoRo5axwzpzU1njj+kqWZHkv7F/Xts0KernTC8L70KQz5zXMe+dO9Lf0dg4EkM7l3E4PhyVm2q4YzSt+g3oAyGHFhxSdkjtAKSqTj7Zkk2xpsJcAoOJpgBEOsFxV0zjM2CAAt0u3CgJkw+n5agL8l+FQzo3/GinyJydPn0MYM4bcJgZk/Kc22sQ+SEEX0pjAUUF6QLOMuhV9a/hMJYwMdbd+W7K4ecMjOkxzlSxhHK4TW1vB9Tyg7P+McjVuEASgceyzE1HzKsIMHYfkkovzSdCSAHxYJC3BtJpBIUhHsyCxrijelgRqZp2aRH6N+7N2Uzv06/Xj0g80pE8iYWBkdMwc9MCmMBs09IF0TXPfzhEQsDRg/sxcdbd+HuR/S9r4IZInLUOJIv5oeLDZrBifWVmK0hGPwp6FWe7y71aGFQSOBOU6Jpr2BGU6KJgBQFoYIZPdmE4UfuFxQRkY46bnj3HV5ypBo/pJTKLTup3tHM0L5H7r2EwmMiItJxfY4lLOpLUNQfhqkOQGeFYSHmTnNy77oZjfFmws4MMxEREZGj1thBpZjB6iN8qIkyM0REpOOCEMZ9ASwG4cFP2ytpQVCIkaJ5nyKgDfFGQktRENMQBRERETkwpUUxhvctZsP2xnx35ZBSMENERA5MFxWWFAjDonQwY9/MjEQTAU5hwZGbGioiIiKHzsUnjqRXwZFd10zBDBERkTyJBcUEnqIp0bRXe1M8HcwoUmaGiIiIHITeRUf+V33VzBAREcmTMCxK18xIZMvMUDBDREREJBMFM0RERPIkFhYRZBhm0hRvJGYQazPDiYiIiIjsoWCGiIhInsRaa2Yk9g9mBBYSBApmiIiIiGSiYIaIiEieBEEBIbZfzYzmRCOBxbDgyB/vKiIiInIwFMwQERHJEwtCYhbuN8ykJbErnZkRHtlVyEVEREQOloIZIiIieWJBjJBgv8yMeKKJgJDAlJkhIiIikomCGSIiInliQUiBBTS0NO7V3pJI18ywQJkZIiIiIpkomCEiIpInQRASM6NpnwKg8UQjocUIQmVmiIiIiGSiYIaIiEiemMWIWbB/MCOZzswIVQBUREREJKNOBTPM7EozW25mKTObsc+yb5pZpZmtNLPz27TPjdoqzeyONu3jzOyvZvaRmT1mZoVRe1H0ujJaPra9fYiIiPQEtjszY0/NjEQqQSoVj6ZmVTBDREREJJPOZmYsAy4HXm/baGaTgKuBycBc4N/MLDSzELgXuACYBHw+WhfgB8Dd7j4RqAVuiNpvAGrdfQJwd7Re1n108nhEREQOGwvSmRkNbYIZzYlmzJ2YxUAfayIiIiIZdSqY4e4r3H1lhkXzgPnu3uzuHwOVwMzoUenuq929BZgPzDMzA84Bnoje/zBwWZttPRw9fwI4N1o/2z5ERER6BLMYMYyWeDMpTwFEWRrJ9BATZWaIiIiIZHSoamaUAevavK6K2rK1DwK2u3tin/a9thUtr4vWz7YtERGRHiEIYwQW4p6iJdkCQHMynZkRWqjMDBEREZEs2v3Jx8xeBIZnWPQtd38q29sytDmZgyeeY/1c28r1nr07Y3YjcCPA6NGjM60iIiJy2AVBmJ6C1VM0J5opjhXTlGjCPJXOzFAwQ0RERCSjdoMZ7j77ILZbBYxq87oc2BA9z9S+FehvZrEo+6Lt+q3bqjKzGNAP2NbOPvY9hvuB+wFmzJiRMeAhIiJyuFkQElgMc6cp0UQ/+qWHmXiKmIIZIiIiIlkdqmEmTwNXRzORjAMmAm8CbwETo5lLCkkX8Hza3R14Bbgiev/1wFNttnV99PwK4OVo/Wz7EBER6RGCID3MBJI0J9PTszYlmghJaZiJiIiISA6dqixmZp8F/h8wBPiDmS1x9/PdfbmZPQ68DySAr7h7MnrPLcDzQAg86O7Lo83dDsw3s38G3gEeiNofAH5pZpWkMzKuBsi1DxERkZ7AgpCAEFJOcyIdzGhONIO7hpmIiIiI5NCpYIa7/w74XZZl3wO+l6H9WeDZDO2ryTAbibs3AVceyD5ERER6gtbMDPO9MzMCXMNMRERERHI4VMNMREREpB2ts5kQ1cyAdDAjZiGBmYIZIiIiIlkomCEiIpIngcX2ms0E0lOzFhBihoIZIiIiIlkomCEiIpInQRgSEBAYew0zKQhi6fnHFcwQERERyUjBDBERkTwJghiYUWix3ZkZTYkmCizEzCDoVGkrERERkSOWghkiIiJ5EoTpzIsCi+2umdGcaCYkCmak8zNEREREZB8KZoiIiORJGBYAUBCEew0ziQUhBCHpwhkiIiIisi8FM0RERPLEomEkBfsMMyn0ADMNMRERERHJRsEMERGRPAmjYEZhNMzE3WlONhMGAWb6iBYRERHJRndKIiIieRLuzswIaE42E0/FSXmKGAGuzAwRERGRrBTMEBERyRMLQgyIWUhzonl3EdCYhZimZRURERHJSsEMERGRPLEghhkUWLoAaGswIyTAAgUzRERERLJRMENERCRfLD0Fa8xCEqkEu1p2ARBiCmaIiIiI5KBghoiISL5YNMwk+jiub64H0pkZWEEeOyYiIiLSvSmYISIiki8WEli6RgZAXXMd0JqZoY9oERERkWx0pyQiIpIvFmBmpPMzoK6pDncnNMM0m4mIiIhIVgpmiIiI5IsZWEiMPZkZKU8PO1HNDBEREZHsFMwQERHJpyBGaHsyMwILCHEIlJkhIiIiko2CGSIiIvlkIUHrMJPmOgrDIgJLESgzQ0RERCQrBTNERETyyCxMz14CtCRb0sEMUpgpmCEiIiKSTaeCGWb2IzP7wMyWmtnvzKx/m2XfNLNKM1tpZue3aZ8btVWa2R1t2seZ2V/N7CMze8zMCqP2ouh1ZbR8bHv7EBER6THaBDMACoNizJOgzAwRERGRrDqbmfECMMXdpwEfAt8EMLNJwNXAZGAu8G9mFlr6Z6Z7gQuAScDno3UBfgDc7e4TgVrghqj9BqDW3ScAd0frZd1HJ49HRETk8ApiBJ4iFtXIKAgKMVIEqpkhIiIiklWnghnu/t/unoheLgTKo+fzgPnu3uzuHwOVwMzoUenuq929BZgPzDMzA84Bnoje/zBwWZttPRw9fwI4N1o/2z5ERER6DLMA9yRFYRFANMwkqZoZIiIiIjl0Zc2MLwJ/jJ6XAevaLKuK2rK1DwK2twmMtLbvta1oeV20frZt7cfMbjSzRWa2qLq6+qAOTkRE5JAIYulgRiwdzCgIizBSWFCQ546JiIiIdF/tBjPM7EUzW5bhMa/NOt8CEsCvWpsybMoPov1gtrV/o/v97j7D3WcMGTIk0yoiIiJ5YRZCKkFxrBjYUzNDIydFREREsmt3QK67z8613MyuBy4GznX31mBCFTCqzWrlwIboeab2rUB/M4tF2Rdt12/dVpWZxYB+wLZ29iEiItIjmIW4J3YPM4kFBenZTDTMRERERCSrzs5mMhe4HbjU3RvaLHoauDqaiWQcMBF4E3gLmBjNXFJIuoDn01EQ5BXgiuj91wNPtdnW9dHzK4CXo/Wz7UNERKTHsCDEU3uGmRQGBYCrAKiIiIhIDp29U/opUAS8kK7JyUJ3/7K7Lzezx4H3SQ8/+Yq7JwHM7BbgeSAEHnT35dG2bgfmm9k/A+8AD0TtDwC/NLNK0hkZVwPk2oeIiEhPYRYDT+4ZZmLpWhkKZoiIiIhk16k7pWi61GzLvgd8L0P7s8CzGdpXk2E2EndvAq48kH2IiIj0FBaE0GY2kwJLJ00GoYaZiIiIiGTTlbOZiIiIyIEKCtLBjL2GmQCqmSEiIiKSlYIZIiIieRTsk5kRIxpmYhpmIiIiIpKNghkiIiL5FIR4m5oZBdGUrEGoYIaIiIhINrpTEhERySOzEPMkJwyeRGABxU292Y6CGSIiIiK5KDNDREQkjyyIEZCkICxi+ojpuCcADTMRERERyUXBDBERkTyyIJ2ZkUw5AKlkFMzQ1KwiIiIiWSmYISIikkdBECMgRcrTwQxPpYMZpqlZRURERLJSMENERCSPAgsBJ5lMApBKpf8NlZkhIiIikpWCGSIiInlkQToDIxUFM1ozMzTMRERERCQ7BTNERETyyKJZS5JREMNTSQzNZiIiIiKSi4IZIiIieZQeZgLJqPBnyhOYAaaaGSIiIiLZKJghIiKSR62ZGa3DS1LJBGamYIaIiIhIDgpmiIiI5FEQFABthpl4kkCZGSIiIiI5KZghIiKSR+HuAqBta2YYmGpmiIiIiGSjYIaIiEgetQ4zSbUtAKrMDBEREZGcFMwQERHJoyDKwNgzNWtcwQwRERGRdiiYISIikkdBmA5auMejf5MEKgAqIiIikpOCGSIiInkU7K6Z0ZqZkcAATB/RIiIiItl06k7JzL5rZkvNbImZ/beZjYzazczuMbPKaPlJbd5zvZl9FD2ub9N+spm9F73nHjOzqH2gmb0Qrf+CmQ1obx8iIiI9RRCkh5kkowKgeAqCkPRYExERERHJpLM/+/zI3ae5ewXwX8C3o/YLgInR40bgZ5AOTADfAU4FZgLfaQ1OROvc2OZ9c6P2O4CX3H0i8FL0Ous+REREepIgKgDq3iYzQzOZiIiIiOTUqWCGu9e3eVkKePR8HvCIpy0E+pvZCOB84AV33+butcALwNxoWV93X+DuDjwCXNZmWw9Hzx/epz3TPkRERHqM1swMj2YzSaWSuIaYiIiIiOTU6Z9+zOx7wHVAHXB21FwGrGuzWlXUlqu9KkM7wDB33wjg7hvNbGg7+9iYoY83ks7eYPTo0Qd2gCIiIodQuHtq1nRmBp7EVPxTREREJKd2f/oxsxfNbFmGxzwAd/+Wu48CfgXc0vq2DJvyg2jP2bWOvsfd73f3Ge4+Y8iQIe1sVkRE5PDZNzPDPQFBQT67JCIiItLttZuZ4e6zO7itXwN/IF0TowoY1WZZObAhaj9rn/ZXo/byDOsDbDazEVFWxghgS9SebR8iIiI9RmswY3dmRioqACoiIiIiWXV2NpOJbV5eCnwQPX8auC6acWQWUBcNFXkemGNmA6LCn3OA56NlO8xsVjSLyXXAU2221TrryfX7tGfah4iISI/ROszEdw8zSWAKZoiIiIjk1NmaGd83s+OAFPAJ8OWo/VngQqASaAD+FsDdt5nZd4G3ovX+t7tvi57fDDwElAB/jB4A3wceN7MbgLXAlbn2ISIi0pNYEMNoM8wklVDNDBEREZF2dCqY4e6fy9LuwFeyLHsQeDBD+yJgSob2GuDcA9mHiIhIj2EhgUEqCmbgSVAwQ0RERCQnzf0mIiKSTxZgZrinh5l4KqlhJiIiIiLtUDBDREQknywAC9rUzEhC0OmZ00VERESOaApmiIiI5JkFIZ6KR6+SBBpmIiIiIpKTghkiIiJ5F+7JzEglwZSZISIiIpKLghkiIiL5FqSDGe6OexIL9PEsIiIikovulkRERPLNYrgnSTkEnsSCgnz3SERERKRbUzBDREQkz8xCPJUg5Y6h2UxERERE2qNghoiISL4FAe5JkiknIIlpNhMRERGRnBTMEBERyTeL4alklJmRwjSbiYiIiEhOCmaIiIjkmQUx8ATJlGOeJFBmhoiIiEhOCmaIiIjkmVmYLgCagoCUZjMRERERaYfulkRERPItCMGTpFJJwFUzQ0RERKQdCmaIiIjkmVkMUkmSqQSAhpmIiIiItEPBDBERkTxLT82aJJVM7H4tIiIiItkpmCEiIpJnFoTgCVJRZoaFBXnukYiIiEj3pmCGiIhInllUMyOZjAMQBMrMEBEREclFwQwREZF8C9KzmZBKpl8qmCEiIiKSk4IZIiIieWYWw7xNAdBQBUBFREREcumSYIaZfcPM3MwGR6/NzO4xs0ozW2pmJ7VZ93oz+yh6XN+m/WQzey96zz1mZlH7QDN7IVr/BTMb0N4+REREepIgiAqARpkZZgpmiIiIiOTS6WCGmY0CzgPWtmm+AJgYPW4EfhatOxD4DnAqMBP4TmtwIlrnxjbvmxu13wG85O4TgZei11n3ISIi0uNYAfie2Uw0NauIiIhIbl2RmXE38L8Ab9M2D3jE0xYC/c1sBHA+8IK7b3P3WuAFYG60rK+7L3B3Bx4BLmuzrYej5w/v055pHyIiIj1KEIYEJEm0FgANVTNDREREJJdOBTPM7FJgvbu/u8+iMmBdm9dVUVuu9qoM7QDD3H0jQPTv0Hb2kamfN5rZIjNbVF1d3cGjExEROTwsCDFSJBJRZoaGmYiIiIjk1O7dkpm9CAzPsOhbwD8BczK9LUObH0R7zq519D3ufj9wP8CMGTPa266IiMhh1VojI5lsBpSZISIiItKedoMZ7j47U7uZTQXGAe9GtTrLgcVmNpN0lsSoNquXAxui9rP2aX81ai/PsD7AZjMb4e4bo2EkW6L2bPsQERHpUVqnYk3Go2CGamaIiIiI5HTQw0zc/T13H+ruY919LOngwknuvgl4GrgumnFkFlAXDRF5HphjZgOiwp9zgOejZTvMbFY0i8l1wFPRrp4GWmc9uX6f9kz7EBER6VEs2DczoyCf3RERERHp9g7VTz/PAhcClUAD8LcA7r7NzL4LvBWt97/dfVv0/GbgIaAE+GP0APg+8LiZ3UB6xpQrc+3jYMTjcaqqqmhqajrYTfRoxcXFlJeXU1Cgm2cRkXxozcxIJZSZISIiItIRXXa3FGVntD534CtZ1nsQeDBD+yJgSob2GuDcDO1Z93Ggqqqq6NOnD2PHjiUaMnPUcHdqamqoqqpi3Lhx+e6OiMhRKQjTH8etwYwwVDBDREREJJeumJq1x2tqamLQoEFHXSADwMwYNGjQUZuVIiLSHexXADRQAVARERGRXBTMiByNgYxWR/Oxi4h0B62zl3iyBWNPDQ0RERERyUzBjG6id+/e+7XdeeedlJWVUVFRwaRJk3j00Ufz0DMRETnUgigzw5NNBAaYMjNEREREclEwo5u77bbbWLJkCU899RQ33XQT8Xg8310SEZEutldmhpmCGSIiIiLtUDCjh5g4cSK9evWitrY2310REZEu1joVazqYgYIZIiIiIu3QoNx9vLpyC9U7mrt0m0P6FHHWcUM7tY3FixczceJEhg7t3HZERKT7aS346almzEJQLSMRERGRnBTM6ObuvvtufvGLX7B69Wqee+65fHdHREQOgaC14GeyBddMJiIiIiLtUjBjH53NoOhqt912G9/4xjd48sknue6661i1ahXFxcX57paIiHSh3cGMVAuECmaIiIiItEc1M3qIyy+/nBkzZvDwww/nuysiItLFgjAdzAiJY8rMEBEREWmXghndRENDA+Xl5bsfd911137rfPvb3+auu+4ilUrloYciInKotAYzAm9R8U8RERGRDtAwk26iIwGKk08+mZUrVx6G3oiIyOHUWgDUcDB9NIuIiIi0R5kZIiIieba7ZgakZzMRERERkZwUzBAREcmzsE0wA9XMEBEREWmXghkiIiJ5FiozQ0REROSAKJghIiKSZ0EYw1pfKJghIiIi0i4FM0RERPLNAqw1mqFhJiIiIiLtUjBDREQk38zwaBYTs4I8d0ZERESk+1Mwo5sIw5CKigqmTJnCJZdcwvbt2wHYsGEDV1xxRcb3nHXWWSxatOhwdlNERA4Ra83IUGaGiIiISLs6FcwwszvNbL2ZLYkeF7ZZ9k0zqzSzlWZ2fpv2uVFbpZnd0aZ9nJn91cw+MrPHzKwwai+KXldGy8e2t4+eqKSkhCVLlrBs2TIGDhzIvffeC8DIkSN54okn8tw7ERE55KJaGaZghoiIiEi7uiIz4253r4gezwKY2STgamAyMBf4NzMLLV2i/V7gAmAS8PloXYAfRNuaCNQCN0TtNwC17j4BuDtaL+s+uuB48u5Tn/oU69evB2DNmjVMmTIFgMbGRq6++mqmTZvGVVddRWNj4+73PPDAAxx77LGcddZZfOlLX+KWW24BoLq6ms997nOccsopnHLKKbzxxhuH/4BERKR90TCT4Mj4KBMRERE5pGLtr3JQ5gHz3b0Z+NjMKoGZ0bJKd18NYGbzgXlmtgI4B7gmWudh4E7gZ9G27ozanwB+amaWYx8LOtPx5yqfY9POTZ3ZxH6G9x7O3AlzO7RuMpnkpZde4oYbbthv2c9+9jN69erF0qVLWbp0KSeddBKQHory3e9+l8WLF9OnTx/OOeccTjzxRABuvfVWbrvtNk4//XTWrl3L+eefz4oVK7ru4EREpEuYRb8vKDNDREREpF1ddQ7wqQAADXZJREFUEcy4xcyuAxYBX3f3WqAMWNhmnaqoDWDdPu2nAoOA7e6eyLB+Wet73D1hZnXR+rn2sRczuxG4EWD06NEHcYiHXmNjIxUVFaxZs4aTTz6Z8847b791Xn/9df7hH/4BgGnTpjFt2jQA3nzzTT7zmc8wcOBAAK688ko+/PBDAF588UXef//93duor69nx44d9OnT51AfkoiIHIjWYSZ2qH5nEBERETlytHvHZGYvAsMzLPoW6cyJ7wIe/fsT4IuAZVjfyTysxXOsT45lud6zd6P7/cD9ADNmzMi4TquOZlB0tdaaGXV1dVx88cXce++9uwMXbZntf9ju2Q8plUqxYMECSkpKurS/IiLSxYJoNhNlZoiIiIi0q92aGe4+292nZHg85e6b3T3p7ingF+wZSlIFjGqzmXJgQ472rUB/2/NzVGv7XtuKlvcDtuXYVo/Wr18/7rnnHn784x8Tj8f3WnbmmWfyq1/9CoBly5axdOlSAGbOnMlrr71GbW0tiUSC3/72t7vfM2fOHH7605/ufr1kyZLDcBQiInKgTJkZIiIiIh3W2dlMRrR5+VlgWfT8aeDqaCaSccBE4E3gLWBiNHNJIekCnk97OrXgFaB1DtLrgafabOv66PkVwMvR+tn20eNNnz6dE088kfnz5+/VfvPNN7Nz506mTZvGD3/4Q2bOTMeOysrK+Kd/+idOPfVUZs+ezaRJk+jXrx8A99xzD4sWLWLatGlMmjSJ++6777Afj4iIdECUkRGEyswQERERaU9nf/75oZlVkB7esQa4CcDdl5vZ48D7QAL4irsnAczsFuB5IAQedPfl0bZuB+ab2T8D7wAPRO0PAL+MCnxuIx0AybmPnmjnzp17vX7mmWd2P1+2LB0jKikp2S/A0eqaa67hxhtvJJFI8NnPfpY5c+YAMHjwYB577LFD1GsREekquyfkUmaGiIiISLs6dcfk7l/Isex7wPcytD8LPJuhfTV7hqm0bW8CrjyQfRyN7rzzTl588UWampqYM2cOl112Wb67JCIiB6B1eIkFCmaIiIiItEd3TEeIH//4x/nugoiIdEYUxAhUAFRERESkXZ2qmSEiIiJdo3UWk0CZGSIiIiLtUjBDRESkG9g9m4kyM0RERETapWCGiIhIdxAomCEiIiLSUQpmiIiIdAOtBUA1zERERESkfQpmdBO9e/fOdxdERCSPgt2ZGQpmiIiIiLRHwQwREZHuQLOZiIiIiHSYghnd2DPPPMOpp57K9OnTmT17Nps3bwbgtddeo6KigoqKCqZPn86OHTvYuHEjZ555JhUVFUyZMoU//elPADz66KNMnTqVKVOmcPvtt+fzcEREJIcgKgAaKjNDREREpF26Y9rXhuegaVPXbrN4OIyce8BvO/3001m4cCFmxr//+7/zwx/+kJ/85Cf8+Mc/5t577+W0005j586dFBcXc//993P++efzrW99i2QySUNDAxs2bOD222/n7bffZsCAAcyZM4ff//73XHbZZV17fCIi0nmtGRkKZoiIiIi0S3dM3VhVVRVXXXUVGzdupKWlhXHjxgFw2mmn8bWvfY1rr72Wyy+/nPLyck455RS++MUvEo/Hueyyy6ioqODll1/mrLPOYsiQIQBce+21vP766wpmiIh0Q63DS4JQH80iIiIi7dEd074OIoPiUPnqV7/K1772NS699FJeffVV7rzzTgDuuOMOLrroIp599llmzZrFiy++yJlnnsnrr7/OH/7wB77whS/wj//4j/Tt2ze/ByAiIh3WOotJqJoZIiIiIu1SMKMbq6uro6ysDICHH354d/uqVauYOnUqU6dOZcGCBXzwwQeUlJRQVlbGl770JXbt2sXixYu5/fbbufXWW9m6dSsDBgzg0Ucf5atf/Wq+DkdERHIwzWYiIiIi0mG6Y+omGhoaKC8v3/36a1/7GnfeeSdXXnklZWVlzJo1i48//hiAf/3Xf+WVV14hDEMmTZrEBRdcwPz58/nRj35EQUEBvXv35pFHHmHEiBH8y7/8C2effTbuzoUXXsi8efPydYgiIpKDBQWACoCKiIiIdIS5e777cFjNmDHDFy1atFfbihUrOOGEE/LUo+5BfwMRkfyq/OA1qj94gkln/3/06zc0390RERERyQsze9vdZ7S3nn7+ERER6QbKR58I8Tr69hmc766IiIiIdHsKZoiIiHQDxb36M2HqpfnuhoiIiEiPEOS7AyIiIiIiIiIiB0LBjMjRVjukraP52EVERERERKTn6XQww8y+amYrzWy5mf2wTfs3zawyWnZ+m/a5UVulmd3Rpn2cmf3VzD4ys8fMrDBqL4peV0bLx7a3jwNVXFxMTU3NUfml3t2pqamhuLg4310RERERERER6ZBO1cwws7OBecA0d282s6FR+yTgamAyMBJ40cyOjd52L3AeUAW8ZWZPu/v7wA+Au919vpndB9wA/Cz6t9bdJ5jZ1dF6V2Xbh7snD/Q4ysvLqaqqorq6+mD/FD1acXHxXtPCioiIiIiIiHRnnS0AejPwfXdvBnD3LVH7PGB+1P6xmVUCM6Nlle6+GsDM5gPzzGwFcA5wTbTOw8CdpIMZ86LnAE8APzUzy7GPBQd6EAUFBYwbN+5A3yYiIiIiIiIiedDZYSbHAmdEwz9eM7NTovYyYF2b9aqitmztg4Dt7p7Yp32vbUXL66L1s21rP2Z2o5ktMrNFR2v2hYiIiIiIiMiRot3MDDN7ERieYdG3ovcPAGYBpwCPm9l4wDKs72QOnniO9cmxLNd79m50vx+4H2DGjBlHX2EMERERERERkSNIu8EMd5+dbZmZ3Qw86enKmW+aWQoYTDpLYlSbVcuBDdHzTO1bgf5mFouyL9qu37qtKjOLAf2Abe3sQ0RERERERESOUJ2tmfF70rUuXo0KfBaSDkw8DfzazO4iXZxzIvAm6WyKiWY2DlhPuoDnNe7uZvYKcAUwH7geeCrax9PR6wXR8pej9bPtI6e33357q5l90snjzofBpP+2IkcDne9yNNH5LkcLnetyNNH5LkeTrj7fx3Rkpc4GMx4EHjSzZUALcH2UpbHczB4H3gcSwFdaZxkxs1uA54EQeNDdl0fbuh2Yb2b/DLwDPBC1PwD8MirwuY10AAR3z7qPXNx9SCePOS/MbJG7z8h3P0QOB53vcjTR+S5HC53rcjTR+S5Hk3yd75aOPUh3pwuiHE10vsvRROe7HC10rsvRROe7HE3ydb53djYTEREREREREZHDSsGMnuP+fHdA5DDS+S5HE53vcrTQuS5HE53vcjTJy/muYSYiIiIiIiIi0qMoM0NEREREREREehQFM7o5M5trZivNrNLM7sh3f0S6mpmtMbP3zGyJmS2K2gaa2Qtm9lH074B891PkYJjZg2a2JZr1q7Ut4/ltafdE1/ulZnZS/noucuCynO93mtn66Bq/xMwubLPsm9H5vtLMzs9Pr0UOjpmNMrNXzGyFmS03s1ujdl3j5YiS41zP+/VdwYxuzMxC4F7gAmAS8Hkzm5TfXokcEme7e0WbKsh3AC+5+0Tgpei1SE/0EDB3n7Zs5/cFwMTocSPws8PUR5Gu8hD7n+8Ad0fX+Ap3fxYgup+5GpgcveffovsekZ4iAXzd3U8AZgFfic5rXePlSJPtXIc8X98VzOjeZgKV7r7a3VuA+cC8PPdJ5HCYBzwcPX8YuCyPfRE5aO7+OrBtn+Zs5/c84BFPWwj0N7MRh6enIp2X5XzPZh4w392b3f1joJL0fY9Ij+DuG919cfR8B7ACKEPXeDnC5DjXszls13cFM7q3MmBdm9dV5D5xRHoiB/7bzN42sxujtmHuvhHSF1BgaN56J9L1sp3fuubLkeqWKK3+wTbDBnW+yxHDzMYC04G/omu8HMH2Odchz9d3BTO6N8vQpuln5EhzmrufRDr98itmdma+OySSJ7rmy5HoZ8AxQAWwEfhJ1K7zXY4IZtYb+C3wP929PteqGdp0zkuPkeFcz/v1XcGM7q0KGNXmdTmwIU99ETkk3H1D9O8W4Hek09A2t6ZeRv9uyV8PRbpctvNb13w54rj7ZndPunsK+AV7Uo11vkuPZ2YFpL/c/crdn4yadY2XI06mc707XN8VzOje3gImmtk4MyskXUjl6Tz3SaTLmFmpmfVpfQ7MAZaRPs+vj1a7HngqPz0UOSSynd9PA9dFFe9nAXWtqcoiPdU+NQE+S/oaD+nz/WozKzKzcaSLIr55uPsncrDMzIAHgBXuflebRbrGyxEl27neHa7vsUOxUeka7p4ws1uA54EQeNDdl+e5WyJdaRjwu/Q1khjwa3d/zszeAh43sxuAtcCVeeyjyEEzs0eBs4DBZlYFfAf4PpnP72eBC0kXymoA/vawd1ikE7Kc72eZWQXpFOM1wE0A7r7czB4H3iddKf8r7p7MR79FDtJpwBeA98xsSdT2T+gaL0eebOf65/N9fTd3DdUSERERERERkZ5Dw0xEREREREREpEdRMENEREREREREehQFM0RERERERESkR1EwQ0RERERERER6FAUzRERERERERKRHUTBDRERERERERHoUBTNEREREREREpEdRMENEREREREREepT/Hy05tzohNXaoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23d8b6e2400>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18, 4))\n",
    "plt.plot(lr.coef_.squeeze(), label='LR', alpha = 0.5)\n",
    "plt.plot(gs_ridge.best_estimator_.coef_.squeeze(), color = 'green', label='Ridge', alpha =0.5)\n",
    "plt.plot(gs_lasso.best_estimator_.coef_, color = 'orange', label='Lasso', alpha =0.5)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Kernel Ridge\n",
    "Definition from sklearn: Kernel ridge regression (KRR) combines ridge regression (linear least squares with l2-norm regularization) with the kernel trick. It thus learns a linear function in the space induced by the respective kernel and the data.\n",
    "\n",
    "### Kernels\n",
    "A kernel $K(\\cdot,\\cdot): \\mathbb{R}^d \\times \\mathbb{R}^d \\rightarrow$ is a symmetric function defined as follows:\n",
    "\n",
    "For any set of n data points $x_1,...,x_n \\in \\mathbb{R}^d$, the $n \\times n$ matrix $K$, where $K_{ij} = K(x_i, x_j)$, is positive semidefinite.\n",
    "\n",
    "From Mercer's theorem, if the function $K(\\cdot,\\cdot)$ satisfies the above properties, then there exists a mapping $\\pi: \\mathbb{R}^d \\rightarrow \\mathbb{R}^D$ such that\n",
    "$$K(x_i, x_j) = \\pi(x_i)^T\\pi(x_j).$$\n",
    "\n",
    "We usually only define $K(\\cdot,\\cdot)$ and avoid ever using $\\phi(\\cdot)$. However, the kernel $K(\\cdot,\\cdot)$ implies that x_i and x_j have been mapped into a higher, or infinite, dimension $D$ to get the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 10} 0.75619309626\n",
      "R-squared: 0.876486633334\n",
      "RMSE: 23917.0284244\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'alpha': [0.1, 1, 10, 100]}\n",
    "kr = KernelRidge()\n",
    "gs_kr = GridSearchCV(kr, param_grid, cv=5)\n",
    "gs_kr.fit(X_train, y_train)\n",
    "print(gs_kr.best_params_, gs_kr.best_score_)\n",
    "\n",
    "y_pred = gs_kr.predict(X_test)\n",
    "print(\"R-squared:\", gs_kr.score(X_test, y_test))\n",
    "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Regression Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'max_features': 'auto', 'min_samples_split': 9} 0.697995302602\n",
      "0.766038280672\n",
      "32917.181488\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth': np.arange(4,9), \n",
    "              'min_samples_split': np.arange(2,11), \n",
    "              'max_features': ['auto', 'sqrt']}\n",
    "dt = DecisionTreeRegressor()\n",
    "gs_dt = GridSearchCV(dt, param_grid, cv=5)\n",
    "gs_dt.fit(X_train, y_train)\n",
    "print(gs_dt.best_params_, gs_dt.best_score_)\n",
    "\n",
    "y_pred = gs_dt.predict(X_test)\n",
    "print(gs_dt.score(X_test, y_test))\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "\n",
    "Bagging uses the boostrap for regression or classification: **Bagging** = **B**oostrap **agg**regation\n",
    "\n",
    "#### Algorithm\n",
    "For $b = 1,...,B$:\n",
    "1. Draw a boostrap sample $\\mathbb{B}_b$ of size $n$ from training data. (Boostrap = resampling with replacement)\n",
    "2. Train a classifier or regression model $f_b$ on $\\mathbb{B}_b$\n",
    "    - For a new point $x_0$, compute:\n",
    "    $$f_avg(X_0) = \\frac{1}{B}\\sum{b=1}^{B}f_b(X_0)$$\n",
    "    - For regression, f_avg(x_0) is the prediction\n",
    "    - For classification, view f_avg(x_0) as an average over $B$ votes. Pick the majority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bagging(model, X_train, y_train, X_test, y_test, iteration = 10):\n",
    "    bagging = BaggingRegressor(model,\n",
    "                               n_estimators=iteration)\n",
    "    bagging.fit(X_train, y_train)\n",
    "    y_pred = bagging.predict(X_test)\n",
    "    print('R-squared: {} RMSE: {}'.format(bagging.score(X_test, y_test), \n",
    "                                          np.sqrt(mean_squared_error(y_test, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression\n",
      "R-squared: -65639786.51282491 RMSE: 551358181.1400583\n",
      "Ridge Regression\n",
      "R-squared: 0.8960664798194211 RMSE: 21939.567313765543\n",
      "Sparse Regression\n",
      "R-squared: 0.8884988886813485 RMSE: 22724.26461515499\n",
      "Kernel Regression\n",
      "R-squared: 0.8908491365634631 RMSE: 22483.49528643615\n",
      "Decision Tree Regression\n",
      "R-squared: 0.859535004883625 RMSE: 25505.526566497887\n"
     ]
    }
   ],
   "source": [
    "# initiate best models from previous codes\n",
    "lr = LinearRegression()\n",
    "ridge = Ridge(alpha=0.7, normalize=True)\n",
    "lasso = Lasso(alpha=10, normalize=True)\n",
    "kr = KernelRidge(alpha=10)\n",
    "dt = DecisionTreeRegressor(max_depth=7, max_features='auto', min_samples_split=9)\n",
    "\n",
    "models = [lr, ridge, lasso, kr, dt]\n",
    "model_names = ['Linear Regression',\n",
    "               'Ridge Regression',\n",
    "               'Sparse Regression',\n",
    "               'Kernel Regression',\n",
    "               'Decision Tree Regression']\n",
    "for (k, v) in zip(model_names, models):\n",
    "    print(k)\n",
    "    apply_bagging(v, X_train, np.ravel(y_train), X_test, y_test, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Improvement\n",
    "- We can further use the parameter max_features in BaggingRegressor to select a subset of features. However, if we use all features by default setting, bagged regressions are correlated. In general, when bootstrap samples are correlated, the benefit of bagging decreases. This could be the reason why bagging doesn't improve much compare to single models.\n",
    "- Random forests model is a modification of bagging where trees are designed to reduce correlation. The modification is to only consider random subset of dimensions of $x \\in \\mathbb{R}^d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "#### Algorithm\n",
    "Input parameter: $m$ - a positive integer with $m<d$ often $m \\approx \\sqrt{d}$\n",
    "For $b = 1,...,B$:\n",
    "1. Draw a boostrap sample $\\mathbb{B}_b$ of size $n$ from the training data.\n",
    "2. Train a tree classfier on $\\mathbb{B}_b$, where each split is computed as follows:\n",
    "    - Randomly select $m$ dimensions of $x \\in \\mathbb{R}^d$ newly chosen for each $b$.\n",
    "    - Make the best split restricted to that subset of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'max_features': 'auto', 'n_estimators': 500} 0.837605990642\n",
      "0.869178488593 24614.432142\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators':[100, 500, 1000],\n",
    "              'max_depth': np.arange(4, 10), \n",
    "              'max_features': ['auto', 'sqrt']}\n",
    "rf = RandomForestRegressor()\n",
    "gs_rf = GridSearchCV(rf, param_grid, cv=5)\n",
    "gs_rf.fit(X_train, np.ravel(y_train))\n",
    "print(gs_rf.best_params_, gs_rf.best_score_)\n",
    "\n",
    "y_pred = gs_rf.predict(X_test)\n",
    "print(gs_rf.score(X_test, y_test), np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoosting\n",
    "\n",
    "In bagging, each training example is equally likely to be picked. In boosting, the probability of a particular example being in the training set of a particular machine depends on the performance of the prior machines on that sample. In each round, each training samples is assigned a new weight depending on the prediction performance from the previous round. More weights are assigned to samples with worse prediction so that each subsequent machine would focus on training the \"difficult\" samples.\n",
    "\n",
    "#### Algorithm\n",
    "Given $(x_1, y_1),...,(x_n, y_n)$, assign a weight $w_i=1$ for $i = 1,...,n$.\n",
    "\n",
    "For $t = 1,..., T$\n",
    "1. The probability that training sample $i$ is in the training set is $p_i = \\frac{w_i}{\\sum w_i}$ where the summation is over all members of the training set. Pick $n$ samples with replacement to form the training set.\n",
    "2. Construct a regression machine $t$.\n",
    "3. Make prediction $y_i^{(p)}(x_i)$ for $i=1,...,n$ with machine $t$. **Note: $y_i^{(p)}(x_i)$ is not the final prediction.**\n",
    "4. Calculate a loss for $y_i^{(p)}(x_i)$ and $y_i$. The loss function may be of any functional form as long as $L \\in$ [0,1]. If we let $$ D = sup|y_i^{(p)}(x_i)-y_i|  i = 1,...,n,$$ which means D is the largest error, then we have three candidate loss functions:\n",
    "$$L_i=\\frac{|y_i^{(p)}(x_i)-y_i|}{D} \\textit{(linear)}$$\n",
    "$$L_i=\\frac{|y_i^{(p)}(x_i)-y_i|^2}{D^2} \\textit{(square law)}$$\n",
    "$$L_i=1-\\exp\\left[\\frac{-|y_i^{(p)}(x_i)-y_i|}{D}\\right] \\textit{(exponential)}$$\n",
    "5. Calculate aveage loss $\\overline{L}=\\sum_{i=1}^{N_1}L_ip_i$\n",
    "6. Form $\\beta=\\frac{\\overline{L}}{1-\\overline{L}}$. $\\beta$ is a measure of confidence in the predictor. Low $\\beta$ means high confidence in the prediction.\n",
    "7. Update the weights: $w_i \\rightarrow w_i\\beta^{[1-L_i]}$. The smaller the loss, the more weight is reduced , making the sample less likely to be picked in the next round.\n",
    "8. For a particular input $x_i$, each of the $T$ machines makes a prediction $h_t, t=1,...,T$. $h_f$ is cumulative prediction using the $T$ predictors:\n",
    "$$h_f = inf\\bigg\\{y \\in Y: \\sum_{t:h_t\\leq y}log(\\frac{1}{\\beta_t})\\geq\\frac{1}{2}\\sum_{t}log(\\frac{1}{\\beta_t})\\bigg\\}$$\n",
    "This equation is essentially relabel $y_i$ such that $y_i^{(1)}<y_i^{(2)}<,...,y_i^{(T)}$. Then sum the $log(1/\\beta_t)$ until we reach the smallest t that is equal or grater than $\\frac{1}{2}\\sum_{t}log(\\frac{1}{\\beta_t})$. This is the weighted median. If the $\\beta_t$ were all equal, this would be the median.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.876690211953 23897.3098963\n"
     ]
    }
   ],
   "source": [
    "abr = AdaBoostRegressor(DecisionTreeRegressor(max_depth=20), \n",
    "                        n_estimators=100,\n",
    "                        loss='exponential')\n",
    "abr.fit(X_train, np.ravel(y_train))\n",
    "y_pred = abr.predict(X_test)\n",
    "print(abr.score(X_test, y_test), np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 500} 0.851484206112\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [100, 250, 500]}\n",
    "abr = AdaBoostRegressor(DecisionTreeRegressor(max_depth=10))\n",
    "gs_cv = GridSearchCV(abr, param_grid, cv = 5)\n",
    "gs_cv.fit(X_train, np.ravel(y_train))\n",
    "print(gs_cv.best_params_, gs_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.828102282846 28215.3404201\n"
     ]
    }
   ],
   "source": [
    "gbr = GradientBoostingRegressor(learning_rate = 0.01,\n",
    "                                n_estimators = 1000,\n",
    "                                max_depth = 10)\n",
    "gbr.fit(X_train, np.ravel(y_train))\n",
    "y_pred = gbr.predict(X_test)\n",
    "print(gbr.score(X_test, y_test), np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'learning_rate': 0.15555555555555556} 0.870965627566\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [100, 150],\n",
    "              'learning_rate': np.linspace(0.1, 0.2, 10)}\n",
    "gbr = GradientBoostingRegressor(max_depth=8, max_features='sqrt')\n",
    "gs_cv = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=5)\n",
    "gs_cv.fit(X_train, np.ravel(y_train))\n",
    "print(gs_cv.best_params_, gs_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"conclusion\"></a>\n",
    "## Performance & Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 116384.01574647],\n",
       "       [ 158760.01461952],\n",
       "       [ 175540.3231846 ],\n",
       "       ..., \n",
       "       [ 181877.81006835],\n",
       "       [  93139.64124942],\n",
       "       [ 220235.59814217]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_kaggle, y_test_kaggle = house_price_data_cleaning(df_test, drop_cols)\n",
    "lr_kaggle = LinearRegression()\n",
    "lr_kaggle.fit(X, y)\n",
    "y_pred_kaggle = lr_kaggle.predict(X_test_kaggle)\n",
    "y_pred_kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References for Model Introduction and Algorithms\n",
    "- Applied Machine Learning Certification - Columnbia Engineering Executive Education\n",
    "\n",
    "#### Note: The coding was done through personal works and researches and not borrowed from the certification course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle score 0.21015; Rank 3817\n",
    "pd.DataFrame({'Id': df_test.Id.values,\n",
    "              'SalePrice': np.squeeze(y_pred_kaggle)}).to_csv('../project-house-price-prediction/data/pred.csv',\n",
    "                                                             index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle score 0.19031; Rank 3619\n",
    "ridge_kaggle = Ridge(alpha=0.5, normalize=True)\n",
    "ridge_kaggle.fit(X, y)\n",
    "y_pred_kaggle = ridge_kaggle.predict(X_test_kaggle)\n",
    "pd.DataFrame({'Id': df_test.Id.values,\n",
    "              'SalePrice': np.squeeze(y_pred_kaggle)}).to_csv('../project-house-price-prediction/data/pred.csv',\n",
    "                                                              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\byron\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Worse performance than Ridge Regression\n",
    "elastic_net_kaggle = ElasticNet(alpha=0.01, l1_ratio=0.1)\n",
    "elastic_net_kaggle.fit(X, y)\n",
    "y_pred_kaggle = elastic_net_kaggle.predict(X_test_kaggle)\n",
    "pd.DataFrame({'Id': df_test.Id.values,\n",
    "              'SalePrice': np.squeeze(y_pred_kaggle)}).to_csv('../project-house-price-prediction/data/pred.csv',\n",
    "                                                              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.18998; Rank 3587\n",
    "alpha_space = np.linspace(0, 1, 101)\n",
    "param_grid = {'alpha': alpha_space}\n",
    "ridge = Ridge(normalize=True)\n",
    "gm_cv = GridSearchCV(ridge, param_grid, cv=6)\n",
    "gm_cv.fit(X, y)\n",
    "y_pred_kaggle = gm_cv.predict(X_test_kaggle)\n",
    "pd.DataFrame({'Id': df_test.Id.values,\n",
    "              'SalePrice': np.squeeze(y_pred_kaggle)}).to_csv('../project-house-price-prediction/data/pred.csv',\n",
    "                                                              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_space = np.linspace(1, 5, 101)\n",
    "param_grid = {'alpha': alpha_space}\n",
    "kr = KernelRidge()\n",
    "gs_cv = GridSearchCV(kr, param_grid, cv=5)\n",
    "gs_cv.fit(X, y)\n",
    "y_pred_kaggle = gs_cv.predict(X_test_kaggle)\n",
    "pd.DataFrame({'Id': df_test.Id.values,\n",
    "              'SalePrice': np.squeeze(y_pred_kaggle)}).to_csv('../project-house-price-prediction/data/pred.csv',\n",
    "                                                              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-379-6a9b933261c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mgbr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgs_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgbr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mgs_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgs_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0my_pred_kaggle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_kaggle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\byron\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\byron\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\byron\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\byron\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\byron\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\byron\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\byron\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\byron\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\byron\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\byron\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[1;32m-> 1034\u001b[1;33m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[0;32m   1035\u001b[0m         \u001b[1;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\byron\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[0;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1089\u001b[1;33m                                      X_csc, X_csr)\n\u001b[0m\u001b[0;32m   1090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1091\u001b[0m             \u001b[1;31m# track deviance (= loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\byron\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[1;32m--> 788\u001b[1;33m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[1;31m# update tree leaves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\byron\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1125\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\byron\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 0.14760; rank 2759\n",
    "param_grid = {'n_estimators': [50, 80, 100],\n",
    "              'learning_rate': np.linspace(0.1, 0.2, 10)}\n",
    "gbr = GradientBoostingRegressor(max_depth=8)\n",
    "gs_cv = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=5)\n",
    "gs_cv.fit(X, np.ravel(y))\n",
    "y_pred_kaggle = gs_cv.predict(X_test_kaggle)\n",
    "pd.DataFrame({'Id': df_test.Id.values,\n",
    "              'SalePrice': np.squeeze(y_pred_kaggle)}).to_csv('../project-house-price-prediction/data/pred.csv',\n",
    "                                                              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'learning_rate': 0.12} 0.883070305873\n"
     ]
    }
   ],
   "source": [
    "# 0.14385; Rank 2637\n",
    "param_grid = {'learning_rate': np.linspace(0.1, 0.125, 11),\n",
    "              'n_estimators': [100, 120]            \n",
    "              }\n",
    "gbr = GradientBoostingRegressor(max_depth=8, max_features='sqrt', subsample = 0.6)\n",
    "gs_cv = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=5)\n",
    "gs_cv.fit(X, np.ravel(y))\n",
    "print(gs_cv.best_params_, gs_cv.best_score_)\n",
    "y_pred_kaggle = gs_cv.predict(X_test_kaggle)\n",
    "pd.DataFrame({'Id': df_test.Id.values,\n",
    "              'SalePrice': np.squeeze(y_pred_kaggle)}).to_csv('../project-house-price-prediction/data/pred.csv',\n",
    "                                                              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 500, 'learning_rate': 0.12} 0.880555757765\n"
     ]
    }
   ],
   "source": [
    "# 0.14334; Rank 2621\n",
    "param_grid = {'learning_rate': [0.12],\n",
    "              'n_estimators': [100, 500, 1000]\n",
    "              }\n",
    "gbr = GradientBoostingRegressor(subsample=0.6, max_depth=8, max_features='sqrt')\n",
    "gs_cv = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=5)\n",
    "gs_cv.fit(X, np.ravel(y))\n",
    "print(gs_cv.best_params_, gs_cv.best_score_)\n",
    "y_pred_kaggle = gs_cv.predict(X_test_kaggle)\n",
    "pd.DataFrame({'Id': df_test.Id.values,\n",
    "              'SalePrice': np.squeeze(y_pred_kaggle)}).to_csv('../project-house-price-prediction/data/pred.csv',\n",
    "                                                              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 500, 'learning_rate': 0.12} 0.858656448642\n",
      "0.879818737007\n",
      "SalePrice    0.139093\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'learning_rate': [0.12],\n",
    "              'n_estimators': [100, 500]\n",
    "              }\n",
    "gbr = GradientBoostingRegressor(subsample=0.6, max_depth=8, max_features='sqrt')\n",
    "gs_cv = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=5)\n",
    "gs_cv.fit(X_train, np.ravel(y_train))\n",
    "print(gs_cv.best_params_, gs_cv.best_score_)\n",
    "y_pred = gs_cv.predict(X_test)\n",
    "print(gs_cv.score(X_test, y_test))\n",
    "print(np.sqrt(mean_squared_error(y_pred, y_test))/np.mean(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalePrice\n",
       "0     208500\n",
       "1     181500\n",
       "2     223500\n",
       "3     140000\n",
       "4     250000"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_pred - np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 8, 'n_estimators': 1500, 'learning_rate': 0.121} 0.881553951019\n"
     ]
    }
   ],
   "source": [
    "# Try to get best training result\n",
    "param_grid = {'learning_rate': np.linspace(0.115, 0.125, 6),\n",
    "              'n_estimators': [1000, 1500],\n",
    "              'max_depth': [7, 8]\n",
    "              }\n",
    "gbr = GradientBoostingRegressor(subsample=0.6, max_features='sqrt')\n",
    "gs_cv = GridSearchCV(estimator=gbr, param_grid=param_grid, cv=5)\n",
    "gs_cv.fit(X, np.ravel(y))\n",
    "print(gs_cv.best_params_, gs_cv.best_score_)\n",
    "y_pred_kaggle = gs_cv.predict(X_test_kaggle)\n",
    "pd.DataFrame({'Id': df_test.Id.values,\n",
    "              'SalePrice': np.squeeze(y_pred_kaggle)}).to_csv('../project-house-price-prediction/data/pred.csv',\n",
    "                                                              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators': [250, 500, 750],\n",
    "              'max_depth': [10]}\n",
    "rf = RandomForestRegressor(min_samples_split = 5, min_samples_leaf = 3)\n",
    "gs_cv = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5)\n",
    "gs_cv.fit(X, np.ravel(y))\n",
    "#print(gs_cv.score(X_test, y_test))\n",
    "y_pred_kaggle = gs_cv.predict(X_test_kaggle)\n",
    "pd.DataFrame({'Id': df_test.Id.values,\n",
    "              'SalePrice': np.squeeze(y_pred_kaggle)}).to_csv('../project-house-price-prediction/data/pred.csv',\n",
    "                                                              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'n_estimators': 750} 0.851810295887\n"
     ]
    }
   ],
   "source": [
    "print(gs_cv.best_params_, gs_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 500} 0.871623084652\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [100, 250, 500]}\n",
    "abr = AdaBoostRegressor(DecisionTreeRegressor(min_samples_split = 5, \n",
    "                                              min_samples_leaf = 3,\n",
    "                                              max_depth=20))\n",
    "gs_cv = GridSearchCV(abr, param_grid, cv = 5)\n",
    "gs_cv.fit(X, np.ravel(y))\n",
    "print(gs_cv.best_params_, gs_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_kaggle = gs_cv.predict(X_test_kaggle)\n",
    "pd.DataFrame({'Id': df_test.Id.values,\n",
    "              'SalePrice': np.squeeze(y_pred_kaggle)}).to_csv('../project-house-price-prediction/data/pred.csv',\n",
    "                                                              index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
